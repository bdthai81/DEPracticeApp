/**
 * Udemy GCP Certified Professional Data Engineer Practice Exam
 * 
 * Rules: Questions has to be in sequencial order within the list
 *      - Currently 1-200
 *
 *  Data element Template
 * 
    {
        // Question 
        id:
        question:
        options: [

        ],
        answer:
        explanation:
    }
*/

var deupData = [
<<<<<<< HEAD
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 1,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Interquartile range (IQR) can be used to identify outliers in a numerical data(True/False)'},
    {'answer': 'A',
    'explanation': 'A, Dimensionality Reduction Techniques is a method to reduce the number of features and is not a Machine Learning Type',
    'id': 2,
    'options': ['A. Dimensionality Reduction Techniques',
    'B. Supervised Machine Learning',
    'C. Reinforcement Learning',
    'D. Unsupervised Machine Learning'],
    'question': 'Which among below is not a machine learning type?'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 3,
    'options': ['A. Cloud Natural Language',
    'B. Cloud Video Intelligence',
    'C. Cloud Translation',
    'D. Cloud Vision'],
    'question': 'Which GCP ML Service can help extract text in a video,including when in the video the text is detected (timestamp) and the location of the text within the frame (bounding box)?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
    'id': 4,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'App Engine Standard environment supports SSH debugging(True/False)'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/dataflow/docs/',
    'id': 5,
    'options': ['A. Apache Beam',
    'B. Apache Nifi',
    'C. Apache Airflow',
    'D. Apache Crunch'],
    'question': 'Cloud Dataflow uses __________ which is a unified programming model that enables one to develop both batch and streaming pipelines'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/bigquery/docs/bigqueryml-intro',
    'id': 6,
    'options': ['A. Principal Component Analysis',
    'B. K means Algorithm',
    'C. Multiclass logistic regression for classification',
    'D. Random Forest'],
    'question': 'BigQuery ML supports which of the following ML models?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/storage-options/',
    'id': 7,
    'options': ['A. Google Cloud Bigtable',
    'B. Google Cloud Datastore',
    'C. Google Cloud Storage',
    'D. Cloud Storage for Firebase'],
    'question': '________ is a scalable, fully-managed NoSQL document database for your web and mobile applications.'},
    {'answer': 'A',
    'explanation': 'A, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 8,
    'options': ['A. Cloud Vision',
    'B. Cloud Natural Language',
    'C. Cloud Video Intelligence',
    'D. Cloud Translation'],
    'question': 'Which GCP ML Service can help to extract text and identify the language from within an image?'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 9,
    'options': ['A. Cloud Vision',
    'B. Cloud Natural Language',
    'C. Cloud Video Intelligence',
    'D. Cloud Translation'],
    'question': 'Which GCP ML Service can help understand the overall sentiment expressed in a block of text?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
    'id': 10,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'With Regards to instance start up time , App Engine Standard environment is faster than App engine Flexible environment(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/composer/',
    'id': 11,
    'options': ['A. Apache Beam',
    'B. Cloud Composer',
    'C. Apache Crunch',
    'D. Apache Nifi'],
    'question': '________ gives you the ability to connect your pipeline through a single orchestration tool whether your workflow lives on-premises, in multiple clouds, or fully within GCP'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/storage/',
    'id': 12,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Google Cloud Storage supports strongly consistent listing(True/False)'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/spanner/docs/audit-logging',
    'id': 13,
    'options': ['A. Data Access (ADMIN_READ)',
    'B. Data Access (DATA_WRITE)',
    'C. Data Access (DATA_READ)',
    'D. User Access(USER_ACCESS)'],
    'question': 'Which among below is not a category of Data Access audit logs for Cloud Spanner?'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 14,
    'options': ['A. Cloud Video Intelligence',
    'B. Cloud Translation',
    'C. Cloud Natural Language',
    'D. Cloud Vision'],
    'question': 'Which GCP ML Service can help detect and translate a document’s language?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 15,
    'options': ['A. Data Preparation ',
    'B. Modeling Phase',
    'C. Data Understanding',
    'D. Deployment Phase'],
    'question': 'The data mining project manager meets with the production line supervisor to discuss implementation of changes and improvements.Which stage in CRISP-DM does this scenario refer to'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/storage-options/',
    'id': 16,
    'options': ['A. Google Cloud Datastore',
    'B. Google Cloud Bigtable',
    'C. Cloud Storage for Firebase',
    'D. Google Cloud Storage'],
    'question': 'A user wished to store images,videos,objects and blob data in a scalable,fully managed,highly reliable and cost efficient object/blob store.Which GCP storage option is appropriate for this use case?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/best-practices-costs',
    'id': 17,
    'options': ['A. Use a LIMIT clause as a method of cost control',
    'B. Query only the columns that you need.',
    "C. Don't run queries to explore or preview table data.Sample data using preview options",
    'D. Before running queries, preview them to estimate costs.'],
    'question': 'Which among below is not a best practice to control cost in BigQuery?'},
    {'answer': 'C',
    'explanation': 'C, Bianary Dummy Varible helps convert categorical variable into multiple numerical variables',
    'id': 18,
    'options': ['A. Assign numeric values to different levels within a categorical variable and use the numeric values instead',
    'B. Use a classification algorithm instead',
    'C. Convert the categorical variable into binary dummy variables',
    'D. Use the categorical variable as is'],
    'question': 'In order to use categorical variables in a regression problem, which data pre-processing step is needed?'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/dataflow/',
    'id': 19,
    'options': ['A. Dataflow',
    'B. Shell Scripts on Compute Instances',
    'C. Dataproc',
    'D. Cloud SQL'],
    'question': 'Iterative processing and notebooks workloads is recommended to be implemented using which google service?'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/bigquery/docs/bigqueryml-intro',
    'id': 20,
    'options': ['A. Random Forest',
    'B. Naive Bayes',
    'C. Decision Trees',
    'D. Binary logistic regression'],
    'question': 'BigQuery ML supports which of the following ML models?'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 21,
    'options': ['A. Cloud Translation',
    'B. Cloud Video Intelligence',
    'C. Cloud Natural Language',
    'D. Cloud Vision'],
    'question': 'Which GCP ML Service can help track objects within a video?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 22,
    'options': ['A. To provide a framework for interpretability of the results',
    'B. To reduce the number of predictor items',
    'C. To help ensure that the predictor items are independent',
    'D. To predict a value of a target variable'],
    'question': 'Which of the following is not a goal of Dimensionality Reduction techniques?'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 23,
    'options': ['A. Cloud Video Intelligence',
    'B. Cloud Natural Language',
    'C. Cloud Vision',
    'D. Cloud Translation'],
    'question': 'Which GCP ML Service can help identify entities and label by types such as person, organization, location, events, products, and media from within a text?'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/storage-options/',
    'id': 24,
    'options': ['A. Google Cloud Bigtable',
    'B. Google Cloud Storage',
    'C. Google BigQuery ',
    'D. Google Cloud Datastore'],
    'question': 'A user wishes to generate reports on petabyte scale data using a Business Intelligence (BI) tools.Which storage option provides integration with BI tools and supports OLAP workloads up to petabyte-scale?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 25,
    'options': ['A. Classification Algorithms',
    'B.  Clustering Algorithms ',
    'C. Assocition Rules ',
    'D.  Principal Component Analysis'],
    'question': 'A professor is conducting a research to examine the proportion of children whose parents read to them and who are themselves good readers.Which Machine learning algorithm can he/she apply ?'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/bigquery/docs/transfer-service-overview',
    'id': 26,
    'options': ['A. Google Transfer Appliance',
    'B. Google Big Data Service',
    'C. Storage Transfer Service',
    'D. BigQuery Data Transfer Service'],
    'question': 'An organisation wishes to automate data movement from Software as a Service (SaaS) applications such as Google Ads and Google Ad Manager on a scheduled, managed basis.This data is further needed to generate reports'},
    {'answer': 'A',
    'explanation': 'A, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 27,
    'options': ['A. Cloud Video Intelligence',
    'B. Cloud Natural Language',
    'C. Cloud Translation',
    'D. Cloud Vision'],
    'question': 'Which GCP ML Service can help detect adult content within a video?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/pubsub/',
    'id': 28,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Cloud Pub/Sub is a HIPAA-compliant service, offering fine-grained access controls and end-to-end encryption(Tre/False)'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 29,
    'options': ['A. Business Understanding,Data Understanding,Data Preparation ,Modeling Phase,Evaluation Phase',
    'B. Data Understanding,Data Preparation ,Modeling Phase,Evaluation Phase,Deployment Phase',
    'C. Modeling Phase,Evaluation Phase,Deployment Phase',
    'D. Business Understanding,Data Understanding,Data Preparation ,Modeling Phase,Evaluation Phase,Deployment Phase'],
    'question': 'Which option among below represents all the stages in CRISP-DM Methodology'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 30,
    'options': ['A. treat the numerical value directly as a categorical variable',
    'B. use min-max normalization',
    'C. Bin the numerical variable into different categories',
    'D. use mean as a reprsentative value'],
    'question': 'To convert a continuous variable into a categorical variable , which of the following technique can we use?'},
    {'answer': 'A',
    'explanation': 'A, Principal components are orthogonal and independent',
    'id': 31,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Selecting suitable principal components from Principal Component Analysis can help avoid multicollinearity in regression problems (True / False)'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 32,
    'options': ['A. Assocition Rules',
    'B. Neural Networks',
    'C. Factor Analysis',
    'D. Linear Regression'],
    'question': 'Which of the following is a Dimensionality Reduction Method?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/storage/',
    'id': 33,
    'options': ['A. Multi Regional',
    'B. Nearline',
    'C. Coldline',
    'D. Regional'],
    'question': '________ Google Cloud Storage is optimized for fast , highly durable storage for data accessed less than once a month'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 34,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'Z-SCORE Standardization is one of the techniques to normalize numeric variables before applying a machine learning model(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/storage-options/',
    'id': 35,
    'options': ['A. Google Cloud Storage',
    'B. Google Cloud Spanner',
    'C. Google Cloud Datastore',
    'D. Google Cloud Bigtable'],
    'question': 'A financial organisation wishes to develop a glocal application to store transactions happening from different part of the world . The storage system must provide low latency transaction support and horizontal scaling.Which GCP service is appropriate for this use case?'},
    {'answer': 'D',
    'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 36,
    'options': ['A. Cloud Video Intelligence',
    'B. Cloud Vision',
    'C. Cloud Translation',
    'D. Cloud Natural Language'],
    'question': 'Which GCP ML Service can help extract tokens and sentences ,identify parts of speech (PoS), and create dependency parse trees for each sentence within a text?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/datastore/',
    'id': 37,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Cloud Datastore supports ACID transactions,SQL-like queries and indexes(True/False)'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
    'id': 38,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'App Engine Flexible environment supports SSH debugging(True/False)'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/bigqueryml-intro',
    'id': 39,
    'options': ['A. Linear Regression',
    'B. Decision Trees',
    'C. Random Forest',
    'D. Neural Networks'],
    'question': 'BigQuery ML supports which of the following ML models?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
    'id': 40,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'App Engine Flexible environment supports running background processes(True/False)'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 41,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Cross Validation is a technique for insuring that the results uncovered in an analysis are generalizable to an independent,unseen,data set(True/False)'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/pubsub/',
    'id': 42,
    'options': ['A. Cloud SQL',
    'B. Google BigTable',
    'C. Dataflow',
    'D. Google BigQuery'],
    'question': 'Which service in combination with Cloud Pub/Sub can be used to implement exactly once processing of incoming stream messages?'},
    {'answer': 'A',
    'explanation': 'A, Confusion Matrix is used to evaluate classification models',
    'id': 43,
    'options': ['A. Confusion Matrix',
    'B. Root Mean Squared Error (RMSE)',
    'C. Coefficient of Determination (R Square)',
    'D. Mean Absolute Error (MAE)'],
    'question': 'Which of the below measures is not used to evaluate regression models'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/compute/docs/faq',
    'id': 44,
    'options': ['A. Both 1 and 2',
    'B. No , we cannot attach to more than 1 instance',
    'C. Yes if the disk is in read-write mode',
    'D. Yes if the disk is in read-only mode'],
    'question': 'Can we attach a persistent disk to more than one GCP compute instance?'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/bigquery/docs/transfer-service-overview',
    'id': 45,
    'options': ['A. Google Ad Manager',
    'B. Campaign Manager',
    'C. On Premise Oracle Database',
    'D. Google Ads'],
    'question': 'Which of the following is not a supported data source for BigQuery Data Transfer Service'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/dataflow/',
    'id': 46,
    'options': ['A. Dataproc',
    'B. Shell Scripts on Compute Instances',
    'C. Cloud SQL',
    'D. Dataflow'],
    'question': 'A startup wishes to use a data processing platform which supports both batch and streaming applications and they would prefer to have a hands-off/serverless data processing platform.Which GCP service is suited for this'},
    {'answer': 'C',
    'explanation': 'C, Association rules can help create rules on which items are brought together',
    'id': 47,
    'options': ['A. Logistic Regression',
    'B. Principal Component Analysis',
    'C. Association Rules',
    'D. Random Forests'],
    'question': 'A retailer wishes to identify the products which are bought together. Given a dataset containing a customer id, receipt id and the products bought. Which type of Machine Learning algorithm is suited to achieve this?'},
    {'answer': 'D',
    'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 48,
    'options': ['A. phone_call',
    'B. command_and_search',
    'C. default',
    'D. video'],
    'question': 'Which model within Cloud Speech-to-Text API is best for audio that originated from video or includes multiple speakers(typically recorded at an 16khz or higher sampling rate)?'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/dataflow/',
    'id': 49,
    'options': ['A. Cloud SQL',
    'B. Dataflow',
    'C. Dataproc',
    'D. Shell Scripts on Compute Instances'],
    'question': 'Machine learning with Spark ML workloads is recommended to be implemented using which google service?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/memorystore/',
    'id': 50,
    'options': ['A. Cloud Storage for Firebase',
    'B. Cloud Memorystore',
    'C. Google Cloud Storage',
    'D. Google Cloud Datastore'],
    'question': '_______ is a fully-managed in-memory data store service for Redis'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/sql/docs/features',
    'id': 51,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Cloud SQL MySQL Instane supports user defined functions(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/solutions/running-janusgraph-with-bigtable',
    'id': 52,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'JanusGraph a Graph Database can use Cloud BigTable as an underlying storage layer(True/False)'},
    {'answer': 'D',
    'explanation': 'D, Logistic regression can be used to create a classification model in this case',
    'id': 53,
    'options': ['A. Linear Regression',
    'B. Principal Component Analysis',
    'C. Association Rules',
    'D. Logistic Regression'],
    'question': 'A bank wishes to predict that a given loan application will default in future. Given a dataset containing customer demographic information, loan application information, credit score and saving balance account information and a label containing default indicator (Y – Will Default, N – Will Not Default). Which type of Machine Learning algorithm is suited to achieve this?'},
    {'answer': 'C',
    'explanation': 'C, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 54,
    'options': ['A. Cloud Vision',
    'B. Cloud Natural Language',
    'C. Cloud Video Intelligence',
    'D. Cloud Translation'],
    'question': 'Which GCP ML Service can help detect scene changes within a video?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/functions/',
    'id': 55,
    'options': ['A. Cloud Translation',
    'B. Google Cloud Functions',
    'C. Google App Engine',
    'D. Google Compute Engine'],
    'question': '_________is a lightweight compute solution for developers to create single-purpose, stand-alone functions that respond to Cloud events without the need to manage a server or runtime environment.'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/sql/docs/features',
    'id': 56,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Cloud SQL PostgreSQL Instane supports Point-in-time recovery (PITR) (True/False)'},
    {'answer': 'A',
    'explanation': 'A, Clusters identifed can be used as a proxy for multiple features',
    'id': 57,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'A Clustering algorithm can be used as a dimension-reduction tool when a dataset has hundred of attributes(True/False)'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 58,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'In a normal probability plot, if the distribution is normal ,the bulk of the points in the plot should fall on a straight lineTrue/False)'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/dataprep/docs/',
    'id': 59,
    'options': ['A. Cloud Dataprep',
    'B. Apache Nifi',
    'C. Data Studio',
    'D. Cloud SQL'],
    'question': '_______ is used to explore and transform raw data from disparate and/or large datasets into clean and structured data for further analysis and processing.'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/bigqueryml-intro',
    'id': 60,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'BigQuery ML functionality is available by using an external tool such as a Jupyter notebook or business intelligence platform(True/False)'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/dataflow/',
    'id': 61,
    'options': ['A. Shell Scripts on Compute Instances',
    'B. Dataproc',
    'C. Dataflow',
    'D. Cloud SQL'],
    'question': 'Data preprocessing for machine learning workloads is recommended to be implemented using which google service?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 62,
    'options': ['A. Yes', 'B. No'],
    'question': 'A transaction id uniquely identifies a transaction is present in a dataset .The dataset is used to predict whether the transaction is fraudulent or not . Can we safely remove transaction id while training a machine learning model(Yes/No)?'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 63,
    'options': ['A. Cloud Natural Language',
    'B. Cloud Vision',
    'C. Cloud Translation',
    'D. Cloud Video Intelligence'],
    'question': 'Which GCP ML Service can help detect explicit content like adult content or violent content within an image?'},
    {'answer': 'C',
    'explanation': 'C, Clustering algorithms can be used to identify clusters in a data set',
    'id': 64,
    'options': ['A. Association Rules',
    'B. Random Forests',
    'C. Clustering Algorithms',
    'D. Recommendation Algorithms'],
    'question': 'Given a dataset containing customer demographic information and purchase history, we need to segment the customers into multiple segments. Which type of Machine Learning algorithm is suited to achieve this?'},
    {'answer': 'D',
    'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 65,
    'options': ['A. video',
    'B. default',
    'C. command_and_search',
    'D. phone_call'],
    'question': 'Which model within Cloud Speech-to-Text API is best for for audio that originated from a phone call (typically recorded at an 8khz sampling rate)?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/storage-options/',
    'id': 66,
    'options': ['A. Google Cloud Bigtable',
    'B. Google Cloud Datastore',
    'C. Google Cloud Storage',
    'D. Google BigQuery '],
    'question': 'A user wishes to store structured data for high-throughput analytics use case.The storage solution must also provide Low-latency read/write access.Which storage option is appropriate for this use case?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/storage-options/',
    'id': 67,
    'options': ['A. Google BigQuery ',
    'B. Google Cloud Storage',
    'C. Google Cloud Datastore',
    'D. Google Cloud Bigtable'],
    'question': 'Which GCP service provides a scalable, fully-managed Enterprise Data Warehouse (EDW) with SQL and fast response times?'},
    {'answer': 'C',
    'explanation': 'C, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 68,
    'options': ['A. Cloud Natural Language',
    'B. Cloud Translation',
    'C. Cloud Vision',
    'D. Cloud Video Intelligence'],
    'question': 'Which GCP ML Service can help detect popular product logos within an image?'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/storage-options/',
    'id': 69,
    'options': ['A. Google Cloud Storage',
    'B. Google Cloud Bigtable',
    'C. Google Cloud Spanner',
    'D. Google Cloud Datastore'],
    'question': 'Which GCP service provides mission-critical, relational database service with transactional consistency, global scale and high availability?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/dataflow/docs/',
    'id': 70,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Cloud Dataflow can be used to deploy both batch and streaming data processing pipelines(True/False)'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
    'id': 71,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'App Engine Standard environment supports installing third-party binaries(True/False)'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/storage-options/',
    'id': 72,
    'options': ['A. Google Cloud SQL',
    'B. Google Cloud Storage',
    'C. Google Cloud Datastore',
    'D. Google Cloud Bigtable'],
    'question': 'A user wishes to develop an application which caters to operational aspects of the business.For this,he needs an OLTP system to store the data.Which GCP service is appropriate for this use?'},
    {'answer': 'A',
    'explanation': 'A, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 73,
    'options': ['A. Cloud Vision',
    'B. Cloud Natural Language',
    'C. Cloud Video Intelligence',
    'D. Cloud Translation'],
    'question': 'Which GCP ML Service can help detect multiple faces within an image, along with the associated key facial attributes like emotional state or wearing headwear?'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 74,
    'options': ['A. Cloud Video Intelligence',
    'B. Cloud Natural Language',
    'C. Cloud Vision',
    'D. Cloud Translation'],
    'question': 'Which GCP ML Service can help classify text documents in 700+ predefined categories?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 75,
    'options': ['A. Data Preparation ',
    'B. Data Understanding',
    'C. Evaluation Phase',
    'D. Modeling Phase'],
    'question': 'The data mining project manager meets with the data warehousing manager to discuss how the data will be collected.Which stage in CRISP-DM does this scenario refer to'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/composer/docs/',
    'id': 76,
    'options': ['A. Apache Airflow',
    'B. Apache Beam',
    'C. Apache Nifi',
    'D. Apache Crunch'],
    'question': 'Cloud Composer is a managed __________ service that helps you create, schedule, monitor and manage workflows'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/storage/',
    'id': 77,
    'options': ['A. Regional',
    'B. Multi Regional',
    'C. Coldline',
    'D. Nearline'],
    'question': '________ Google Cloud Storage is optimized for geo redundancy and end user latency'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/compute/docs/faq',
    'id': 78,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'A service account is a Google account that represents an end user(True/False)'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 79,
    'options': ['A. Modeling Phase',
    'B. Evaluation Phase',
    'C. Data Preparation ',
    'D. Data Understanding'],
    'question': 'Managers want to know by next week whether deployment will take place.Therefore,analysts meet to discuss how useful and accurate their model is . Which stage in CRISP-DM does this scenario refer to'},
    {'answer': 'C',
    'explanation': 'C, Coefficient of Determination (R Square) is used to evaluate regression models',
    'id': 80,
    'options': ['A. Area Under the Curve (AUC)',
    'B. ROC Chart',
    'C. Coefficient of Determination (R Square)',
    'D. Confusion Matrix'],
    'question': 'Which of the below technique is not used to evaluate classification models'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/spanner/docs/bulk-loading',
    'id': 81,
    'options': ['A. Upload data before creating secondary indexes',
    'B. Commit between 1 MB to 5 MB mutations at a time',
    'C. Partition your data by primary key',
    'D. Sequentially add all rows in primary key order'],
    'question': 'Which among below is an inefficient practice while loading data in Cloud Spanner?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
    'id': 82,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'App Engine Standard environment supports running background processes(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 83,
    'options': ['A. Cloud Translation',
    'B. Cloud Vision',
    'C. Cloud Natural Language',
    'D. Cloud Video Intelligence'],
    'question': 'Which GCP ML Service can help search the internet for similar images?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 84,
    'options': ['A. Data Preparation ',
    'B. Modeling Phase',
    'C. Data Understanding',
    'D. Business Understanding'],
    'question': 'The data mining consultant meets with the vice president for marketing,who says that he would like to move forward with customer relationship management.Which stage in CRISP-DM does this scenario refer to'},
    {'answer': 'A',
    'explanation': 'A, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 85,
    'options': ['A. Cloud Vision',
    'B. Cloud Natural Language',
    'C. Cloud Translation',
    'D. Cloud Video Intelligence'],
    'question': 'Which GCP ML Service can help detect broad sets of categories within an image, ranging from modes of transportation to animals?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/datalab/',
    'id': 86,
    'options': ['A. Dataflow', 'B. Datalab', 'C. Dataproc', 'D. Cloud SQL'],
    'question': '_________ provides a managed Jupyter notebook environment to provide interactive tool for data exploration, analysis, visualization and machine learning'},
    {'answer': 'D',
    'explanation': 'D, Multiple Regression problem as there are multiple features',
    'id': 87,
    'options': ['A. Principal Component Analysis',
    'B. \tSimple Linear Regression Algorithm',
    'C. Naïve Bayes Algorithm',
    'D. Multiple Linear Regression Algorithm'],
    'question': 'Given a dataset containing house attributes and the neighbourhood and locality information and the house price, a realtor wishes to set an appropriate price for a new house. Which type of Machine Learning Algorithm can help achieve this.'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/pubsub/docs/',
    'id': 88,
    'options': ['A. Cloud Pub/Sub', 'B. Dataflow', 'C. Dataproc', 'D. Datalab'],
    'question': '_________ is a fully-managed real-time messaging service that allows you to send and receive messages between independent applications.'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/storage/',
    'id': 89,
    'options': ['A. Coldline',
    'B. Multi Regional',
    'C. Regional',
    'D. Nearline'],
    'question': '________ Google Cloud Storage is optimized for high performance local access.Eg: Whenyou need to support high frequency analytics workload'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/kubernetes-engine/',
    'id': 90,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Google Kubernetes engine provides stateful application support.One can attach persistent storage to containers, and even host complete databases(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/storage-options/',
    'id': 91,
    'options': ['A. Cloud Storage for Firebase',
    'B. Firebase Realtime Database ',
    'C. Google Cloud Datastore',
    'D. Google Cloud Storage'],
    'question': '________ is a realtime ,NoSQL JSON database for developing web and mobile applications.'},
    {'answer': 'D',
    'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 92,
    'options': ['A. video',
    'B. default',
    'C. phone_call',
    'D. command_and_search'],
    'question': 'Which model within Cloud Speech-to-Text API is best for short queries such as voice commands or voice search?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/storage-transfer/docs/',
    'id': 93,
    'options': ['A. Google Transfer Appliance',
    'B. Storage Transfer Service',
    'C. Google Big Data Service',
    'D. BigQuery Data Transfer Service'],
    'question': 'An organisation wishes to move their Online Analytics Data to GCP Cloud Storage.Which service can it use?'},
    {'answer': 'B',
    'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 94,
    'options': ['A. Cloud Natural Language',
    'B. Dialogflow',
    'C. Cloud Vision',
    'D. Cloud Video Intelligence'],
    'question': 'Which GCP Service makes it easy for one to design and integrate a conversational user interface into a mobile app, web application, device, bot, interactive voice response systems, and so on?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/solutions/opentsdb-cloud-platform',
    'id': 95,
    'options': ['A. Google Cloud Storage',
    'B. Google Cloud Bigtable',
    'C. Cloud Storage for Firebase',
    'D. Google Cloud Datastore'],
    'question': 'OpenTSDB can be used to monitor Time-Series Data using which of the below GCP storage service'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/gis-visualize',
    'id': 96,
    'options': ['A. Data Studio',
    'B. Jupyter notebooks ',
    'C. BigQuery Geo Viz',
    'D. Google Earth Engine'],
    'question': 'BigQuery GIS data cannot be currently visualized using ?'},
    {'answer': 'D',
    'explanation': 'D, It is based on definition of Reinforcement learning',
    'id': 97,
    'options': ['A. Unsupervised Machine Learning',
    'B. Supervised Machine Learning',
    'C. Dimensionality Reduction Techniques',
    'D. Reinforcement Learning'],
    'question': '___________ is a type of Machine Learning which aims to maximum a cumulative measure (say a reward) based on interactions with a given system. Eg : A robotic car needs to figure out a best way to traverse a path . The best way is the one with limited hurdles and shortest path.'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/sql/',
    'id': 98,
    'options': ['A. Oracle', 'B. Teradata', 'C. MySQL', 'D. DB2'],
    'question': 'Cloud SQL supports which of the following database engines?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 99,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'K Means Clustering can be used to identify groups of numerical variables.These groups can then be used as categorical variables for models which requires categorical variables as an input(True/False)'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 100,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'MIN-MAX Normalization is one of the techniques to normalize numeric variables before applying a machine learning model(True/False)'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/iam/docs/resource-hierarchy-access-control',
    'id': 101,
    'options': ['A. Grant roles at the smallest scope needed. For example, if a user only needs access to publish messages to a Cloud Pub/Sub topic, grant the Publisher role to the user for that topic.',
    'B. Use the security principle of least privilege to grant Cloud IAM roles; that is, only give the least amount of access necessary to your resources.',
    'C. Use projects to group resources that share the same trust boundary. For example, resources for the same product or microservice can belong to the same project.',
    'D. Grant roles to individual members instead of to a Google group when possible'],
    'question': 'Which of the below is not a best practice for setting Cloud IAM roles?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 102,
    'options': ['A. modified', 'B. synchronize', 'C. upsert', 'D. update'],
    'question': 'Hadoop distcp command can be used to synchronize the target directory with the updated files in the source directory.Which option in distcp can be used to achive this?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/dataflow/',
    'id': 103,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'Cloud Dataflow supports reliable & consistent Exactly-once Processing(True/False)'},
    {'answer': 'B',
    'explanation': 'B, The combiner function helps to cut down the amount of data shuffled between the mappers and reducers and is not a replacement for a reducer function',
    'id': 104,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'A combiner function is a replacement for a reducer function(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/bigquery-connector-for-excel',
    'id': 105,
    'options': ['A. Excel GCP Addin',
    'B. BigQuery Connector for Excel',
    'C. Excel BigQuery Integrator',
    'D. Excel VBA Programming'],
    'question': 'Excel can be used to analyze data in BigQuery using which of the following tools?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 106,
    'options': ['A. balancer', 'B. suffler', 'C. distcp', 'D. datamover'],
    'question': '_______ program is a Hadoop daemon that redistributes blocks by moving them from overutilized datanodes to underutlized datanodes,while adhering to the block replica placement policy that makes data loss unlikely by placing block replicas on different racks'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 107,
    'options': ['A. Data Understanding',
    'B. Model Evaluation',
    'C. Data Preparation ',
    'D. Modeling Phase'],
    'question': 'The analysts meet to discuss whether the neural network or decision tree models should be applied.Which stage in CRISP-DM does this scenario refer to'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/bigquery/external-data-sources',
    'id': 108,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'Data strored in Parquet or ORC format in Cloud Storage can be queried using BigQuery(True/False)'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/trace/docs/',
    'id': 109,
    'options': ['A. Stackdriver Logging',
    'B. Stackdriver Debugger',
    'C. Stackdriver Trace',
    'D. Stackdriver Error Reporting'],
    'question': 'An application developer sees some latency issues in an application running on Google App Engine.Which GCP Service can he use to trace and colllect latency data for further analysis?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/views-intro',
    'id': 110,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'BigQuery views are materialised views and are not logical views(True/False)'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 111,
    'options': ['A. CLUSTERED BY',
    'B. SUBGROUP BY',
    'C. PARTION BY',
    'D. BUCKET BY'],
    'question': 'Which Clause in HiveQL can be used to specify Bucketted Columns at the time of table creation?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 112,
    'options': ['A. HDFS Federation',
    'B. Hadoop Streaming',
    'C. HDFS High Availability',
    'D. Hadoop Batch'],
    'question': 'Hadoop provides a feature whih allows a cluster to scale by adding namenodes,each of which manages a portion of the filesystem namespace.Eg : one namenode might manage all the files rooted under /user,say,and a second namenode might handle files under /share.This feature is termed as ?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 113,
    'options': ['A. Apache Flume',
    'B. Apache Pig',
    'C. Apache Sqoop',
    'D. Apache Hive'],
    'question': '_______ is a scripting and data flow programming language to explore large datasets'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/bigquery/external-data-sources',
    'id': 114,
    'options': ['A. Stackdriver',
    'B. CloudSQL',
    'C. Cloud Spanner',
    'D. Google Cloud Bigtable'],
    'question': 'BigQuery offers support for querying data directly from ?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/debugger/',
    'id': 115,
    'options': ['A. Stackdriver Monitoring',
    'B. Stackdriver Error Reporting',
    'C. Stackdriver Logging',
    'D. Stackdriver Debugger'],
    'question': '_______ aggregates and displays errors produced in your running cloud services.'},
    {'answer': 'A',
    'explanation': 'A, Map outputs are intermediate outputs to be consumed by reducer to generate final outputs.Storing intermediate outputs in HDFS would be an overkill due to HDFS replication',
    'id': 116,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Map tasks write their output to the local disk and not to HDFS(True/False)'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 117,
    'options': ['A. distcp', 'B. distcopy', 'C. cp', 'D. copy'],
    'question': 'Hadoop comes with a program called _______ for copying data to and from Hadoop filesystems in parallel'},
    {'answer': 'A',
    'explanation': 'A, The input to a single reduce task is normally the output from multiple mappers',
    'id': 118,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': "Reduce tasks don't have the advantage of data locality(True/False)"},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
    'id': 119,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'App Engine Standard environment supports writing to local disk(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/iam/docs/resource-hierarchy-access-control',
    'id': 120,
    'options': ['A. Both Bob and Alice have editor and publisher role on topic_new',
    'B. Bob will have editor role on topic_new.Alice will have publisher role on topic_new',
    'C. Bob will not have any role on topic_new.Alice will not have publisher role on topic_new',
    'D. Bob will have editor role on topic_new.Alice will not have any role on topic_new'],
    'question': 'In Cloud Pub/Sub, topics and subscriptions are resources that live under a project. Assume that project_new has a topic topic_new under it. If you set a policy on project_new that grants the editor role to bob@gmail.com, and set a policy on topic_new that grants the publisher role to alice@gmail.com,then which of the following statement is true'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/bigquery/docs/querying-clustered-tables',
    'id': 121,
    'options': ['A. Do not compare clustered columns to other columns',
    "B. Filter clustered columns in the order they're specified",
    'C. Comparing clustered columns with other columns in the where clause will not impact performance',
    'D. Do not use clustered columns in complex filter expressions'],
    'question': 'Which of the following is not recommended to obtain best performance from queries against clustered tables in BigQuery?'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/bigquery/docs/saving-sharing-queries',
    'id': 122,
    'options': ['A. Private',
    'B. Project-level',
    'C. Orgabization-level',
    'D. Public'],
    'question': 'Queries in BigQuery can be saved or shared with others . Which of the below is not a type of saved queries?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/bigquery/quotas#streaming_inserts',
    'id': 123,
    'options': ['A. App Engine , BigQuery Streaming inserts , DataStudio for Visualization',
    'B. App Engine , Data FLow , Jupyter Notebook',
    'C. Compute Engine , Big Query Batch Inserts , Data Studio',
    'D. App Engine , Data Proc , Jupyter Notebook'],
    'question': 'An organisation wishes to enable real time analytics on user interactions on their web application . They estimate that there will be 1000 interactions per second and wishes to use services which are ops free.Which combination of services can be used in this case?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/cached-results',
    'id': 124,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'BigQuery Query Results will not be cached when your query runs against an external data source(True/False)'},
    {'answer': 'A',
    'explanation': 'A, Because it males reading records a non local operation and so it is not recommended for Hadoop',
    'id': 125,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Storing data in a normalized format is usually not recommended for Hadoop (True/False)'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/dataflow/',
    'id': 126,
    'options': ['A. Shell Scripts on Compute Instances',
    'B. Cloud SQL',
    'C. Dataflow',
    'D. Dataproc'],
    'question': 'An orgainisation wishes to move their existing map reduce jobs from on premise to a cloud environment.Which GCP service is suited for this?'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/filestore/docs/',
    'id': 127,
    'options': ['A. Cloud Storage',
    'B. Cloud SQL',
    'C. Cloud Filestore',
    'D. Cloud BigTable'],
    'question': '________ provides a fully managed NFS file servers on Google Cloud Platform (GCP) for use with applications running on Compute Engine virtual machines (VMs) instances or Kubernetes Engine clusters.'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/access-control',
    'id': 128,
    'options': ['A. jobUser', 'B. dataOwner', 'C. user', 'D. dataViewer'],
    'question': 'A BigQuery Administrator wishes to grant a user the priviledge to create jobs/queries and an ability to cancel self submitted jobs.Which role can he assign to the user?'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://www.tensorflow.org/guide/',
    'id': 129,
    'options': ['A. Estimators',
    'B. Importing Data',
    'C. Eager Execution',
    'D. Keras'],
    'question': "_______ is a TensorFlow's high-level API for building and training deep learning models."},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 130,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'Z-SCORE can be used to identify outliers in a numerical data(True/False)'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 131,
    'options': ['A. Hadoop Connector',
    'B. Hadoop Interface Programming',
    'C. Hadoop Streaming',
    'D. Hadoop Batch'],
    'question': 'Hadoop provides an API to MapReduce that allows you to write your map and reduce functions in languages other than Java.This feature is termed as ?'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/querying-wildcard-tables',
    'id': 132,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'In BigQuery,Wildcard tables support native BigQuery storage only. You cannot use wildcards when querying an external table or a view.(True/False)'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/transfer-appliance/docs/2.0/',
    'id': 133,
    'options': ['A. BigQuery Data Transfer Service',
    'B. Storage Transfer Service',
    'C. Google Transfer Appliance',
    'D. Google Big Data Service'],
    'question': 'An organisation wishes to move their Analytics Data from on premise storage to GCP Cloud Storage.Which service can it use?'},
    {'answer': 'D',
    'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
    'id': 134,
    'options': ['A. Cloud Video Intelligence',
    'B. Cloud Natural Language',
    'C. Cloud Translation',
    'D. Cloud Vision'],
    'question': 'Which GCP ML Service can help detect popular natural and man-made structures within an image?'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/debugger/',
    'id': 135,
    'options': ['A. Stackdriver Logging',
    'B. Stackdriver Monitoring',
    'C. Stackdriver Error Reporting',
    'D. Stackdriver Debugger'],
    'question': '_______ is a feature of the Google Cloud Platform that lets you inspect the state of a running application, in real time, without stopping or slowing it down.'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 136,
    'options': ['A. Data Locality',
    'B. Distributed Computing',
    'C. Cloud Computing',
    'D. Rack Awareness'],
    'question': 'Hadoop does its best to run the map task on a node where the input data resides in HDFS.This optimization technique is referred to as?'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/iam/docs/testing-permissions',
    'id': 137,
    'options': ['A. EvaluateIamPermissions()',
    'B. CheckIamPermissions()',
    'C. testIamPermissions()',
    'D. getIamPermissions()'],
    'question': '_______ allows you to test Cloud IAM permissions on a user for a resource.'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 138,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'When you drop an External Table , Hive will leave the data untouched and only delete the metadata(True/False)'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 139,
    'options': ['A. No', 'B. Yes'],
    'question': 'A dataset containing fields (Gender,Age,Occuption,Earnings) has a contant value for field Occupation (say Software Engineer).A classification algorithm to predict the Earnings has an accuracy of 78% . If we remove the field Occupation to re-build the model , will it change the model accuracy(Yes/No)?'},
    {'answer': 'D',
    'explanation': 'D, Please refer https://cloud.google.com/storage-options/',
    'id': 140,
    'options': ['A. Google Cloud Datastore',
    'B. Google Cloud Storage',
    'C. Google Cloud Bigtable',
    'D. Cloud Storage for Firebase'],
    'question': 'A user wishes to develop a mobile app which will capture unstructured/semi-structured data on user interactions with the mobile app.Which GCP storage option is appropriate for this use case?'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/pubsub/',
    'id': 141,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'Cloud Pub/Sub supports At-least-once delivery of messages(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/storage/',
    'id': 142,
    'options': ['A. Multi Regional',
    'B. Coldline',
    'C. Regional',
    'D. Nearline'],
    'question': '________ Google Cloud Storage is optimized for fast , highly durable storage for data accessed less than once a year'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 143,
    'options': ['A. m', 'B. d', 'C. a', 'D. degree'],
    'question': 'The degree of parallelism (number of mappers) for distcp can be controlled by which argument'},
    {'answer': 'A',
    'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
    'id': 144,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'App Engine Flexible environment supports writing to local disk(True/False)'},
    {'answer': 'B',
    'explanation': 'B, YARN supports FIFO,Capacity and Fair Schedulers',
    'id': 145,
    'options': ['A. FIFO', 'B. Complexity based', 'C. Capacity', 'D. Fair'],
    'question': 'Which of the below is not a scheduler option provided by YARN?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 146,
    'options': ['A. Apache Sqoop',
    'B. Apache Flume',
    'C. Apache Hive',
    'D. Apache Pig'],
    'question': '_______ is a framework for data warehousing on top of Hadoop'},
    {'answer': 'B',
    'explanation': 'B, Hive stores table metadata information in a relational database',
    'id': 147,
    'options': ['A. TRUE', 'B. FALSE'],
    'question': 'Hive stores table metadata information in HDFS(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/cached-results',
    'id': 148,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'BigQuery Query Results will not be cached when you are querying multiple tables using a wildcard(True/False)'},
    {'answer': 'B',
    'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/cached-results',
    'id': 149,
    'options': ['A. FALSE', 'B. TRUE'],
    'question': 'BigQuery Query Results will not be cached when the query uses non-deterministic functions; for example, date and time functions such as CURRENT_TIMESTAMP() and NOW(), and other functions such as CURRENT_USER() return different values depending on when a query is executed(True/False)'},
    {'answer': 'C',
    'explanation': 'C, Please refer https://cloud.google.com/iam/docs/understanding-service-accounts',
    'id': 150,
    'options': ['A. Do not delete service accounts that are in use by running instances on Google App Engine or Google Compute Engine.',
    'B. Use the display name of a service account to keep track of the service accounts. When you create a service account, populate its display name with the purpose of the service account.',
    'C. Avoid rotation of user-managed service account keys',
    'D. Restrict who can act as service accounts. Users who are Service Account Users for a service account can indirectly access all the resources the service account has access to. Therefore, be cautious when granting the serviceAccountUser role to a user.'],
    'question': 'Which of the below is not a best practice with relation to setting up a service account?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 151,
    'options': ['A. Use Cloud SQL for storage. Use Cloud Dataflow to transform data to support query patterns.',
    'B. Use Cloud SQL for storage. Add secondary indexes to support query patterns.',
    'C. Use Cloud Spanner for storage. Add secondary indexes to support query patterns.',
    'D. Use Cloud Spanner for storage. Use Cloud Dataflow to transform data to support query patterns.'],
    'question': 'You are designing storage for two relational tables that are part of a 10-TB database on Google Cloud. You want to support transactions that scale horizontally. You also want to optimize data for range queries on nonkey columns. What should you do?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 152,
    'options': ["A. 'bigquery-public-data.noaa_gsod.gsod'*",
    'B. bigquery-public-data.noaa_gsod.gsod*',
    "C. 'bigquery-public-data.noaa_gsod.gsod*`",
    "D. 'bigquery-public-data.noaa_gsod.gsod'"],
    'question': "Your company is using WHILECARD tables to query data across multiple tables with similar names. The SQL statement is currently failing with the following error:# Syntax error : Expected end of statement but got “-“ at [4:11] SELECT age FROM bigquery-public-data.noaa_gsod.gsod WHERE age != 99 AND_TABLE_SUFFIX = '1929' ORDER BY age DESC Which table name will make the SQL statement work correctly?"},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 153,
    'options': ['A. Issue a command to restart the database servers.',
    'B. Reduce the query frequency to once every hour until the database comes back online.',
    'C. Retry the query with exponential backoff, up to a cap of 15 minutes.',
    'D. Retry the query every second until it comes back online to minimize staleness of data.'],
    'question': 'Your weather app queries a database every 15 minutes to get the current temperature. The frontend is powered by Google App Engine and server millions of users. How should you design the frontend to respond to a database failure?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 154,
    'options': ['A. Switch Cloud Dataflow to pull messages from Cloud Pub/Sub instead of Cloud Pub/Sub pushing messages to Cloud Dataflow.',
    'B. Check the dashboard application to see if it is not displaying correctly.',
    'C. Use Google Stackdriver Monitoring on Cloud Pub/Sub to find the missing messages.',
    'D. Run a fixed dataset through the Cloud Dataflow pipeline and analyze the output.'],
    'question': 'Your software uses a simple JSON format for all messages. These messages are published to Google Cloud Pub/Sub, then processed with Google Cloud Dataflow to create a real-time dashboard for the CFO. During testing, you notice that some messages are missing in the dashboard. You check the logs, and all messages are being published to Cloud Pub/Sub successfully. What should you do next?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 155,
    'options': ['A. Use pre-emptible virtual machines (VMs) for the cluster',
    'B. Use SSDs on the worker nodes so that the job can run faster',
    'C. Use a higher-memory node so that the job runs faster',
    'D. Migrate the workload to Google Cloud Dataflow'],
    'question': 'Your analytics team wants to build a simple statistical model to determine which customers are most likely to work with your company again, based on a few different metrics. They want to run the model on Apache Spark, using data housed in Google Cloud Storage, and you have recommended using Google Cloud Dataproc to execute this job. Testing has shown that this workload can run in approximately 30 minutes on a 15-node cluster, outputting the results into Google BigQuery. The plan is to run this workload weekly. How should you optimize the cluster for cost?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 156,
    'options': ['A.  E. Create a Hadoop cluster on Google Compute Engine that uses Local SSD disks.',
    'B. Create a Google Cloud Dataflow job to process the data.',
    'C. Create a Cloud Dataproc cluster that uses the Google Cloud Storage connector."',
    'D. Create a Google Cloud Dataproc cluster that uses persistent disks for HDFS.',
    'E. Create a Hadoop cluster on Google Compute Engine that uses persistent disks.'],
    'question': 'Your company is migrating their 30-node Apache Hadoop cluster to the cloud. They want to re-use Hadoop jobs they have already created and minimize the management of the cluster as much as possible. They also want to be able to persist data beyond the life of the cluster. What should you do?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 157,
    'options': ["A. Integrate with a single sign-on (SSO) platform, and pass each user's credentials along with the query request",
    'B. Create groups for your users and give those groups access to the dataset',
    'C. Create a dummy user and grant dataset access to that user. Store the username and password for that user in a file on the files system, and use those credentials to access the BigQuery dataset',
    "D. Create a service account and grant dataset access to that account. Use the service account's private key to access the dataset"],
    'question': "You are integrating one of your internal IT applications and Google BigQuery, so users can query BigQuery from the application's interface. You do not want individual users to authenticate to BigQuery and you do not want to give them access to the dataset. You need to securely access BigQuery from your IT application.What should you do?"},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 158,
    'options': ['A. Call a transform that returns TableRow objects, where each element in the PCollexction represents a single row in the table.',
    'B. Use of both the Google BigQuery TableSchema and TableFieldSchema classes.',
    'C. Specify the TableReference object in the code.',
    'D. Use .fromQuery operation to read specific fields from the table.'],
    'question': 'Your company is performing data preprocessing for a learning algorithm in Google Cloud Dataflow. Numerous data logs are being are being generated during this step, and the team wants to analyze them. Due to the dynamic nature of the campaign, the data is growing exponentially every hour.The data scientists have written the following code to read the data for a new key features in the logs. BigQueryIO.Read.named(“ReadLogData”).from(“clouddataflow-readonly:samples.log_data”).You want to improve the performance of this data read. What should you do?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 159,
    'options': ['A. Build and train a text classification model using TensorFlow. Deploy the model using Cloud Machine Learning Engine. Call the model from your application and process the results as labels.',
    'B. Call the Cloud Natural Language API from your application. Process the generated Entity Analysis as labels.',
    'C. Build and train a text classification model using TensorFlow. Deploy the model using a Kubernetes Engine cluster. Call the model from your application and process the results as labels.',
    'D. Call the Cloud Natural Language API from your application. Process the generated Sentiment Analysis as labels.'],
    'question': "You are developing an application on Google Cloud that will automatically generate subject labels for users' blog posts. You are under competitive pressure to add this feature quickly, and you have no additional developer resources. No one on your team has experience with machine learning. What should you do?"},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 160,
    'options': ['A. Combine highly co-dependent features into one representative feature.',
    'B. Instead of feeding in each feature individually, average their values in batches of 3.',
    'C. Remove the features that have null values for more than 50% of the training records.',
    'D. Eliminate features that are highly correlated to the output labels.'],
    'question': 'You are building a model to predict whether or not it will rain on a given day. You have thousands of input features and want to see if you can improve training speed by removing some features while having a minimum effect on model accuracy. What can you do?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 161,
    'options': ['A. Use Cloud Bigtable for storage. Link as permanent tables in BigQuery for query.',
    'B. Use Cloud Storage for storage. Link as temporary tables in BigQuery for query.',
    'C. Use Cloud Bigtable for storage. Install the HBase shell on a Compute Engine instance to query the Cloud Bigtable data.',
    'D. Use Cloud Storage for storage. Link as permanent tables in BigQuery for query.'],
    'question': 'You are designing storage for 20 TB of text files as part of deploying a data pipeline on Google Cloud. Your input data is in CSV format. You want to minimize the cost of querying aggregate values for multiple users who will query the data in Cloud Storage with multiple engines. Which storage service and schema design should you use?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 162,
    'options': ['A. The CSV data loaded in BigQuery is not flagged as CSV.',
    'B. The CSV data has invalid rows that were skipped on import.',
    'C. The CSV data has not gone through an ETL phase before loading into BigQuery.',
    "D. The CSV data loaded in BigQuery is not using BigQuery's default encoding."],
    'question': 'Your company is loading comma-separated values (CSV) files into Google BigQuery. The data is fully imported successfully; however, the imported data is not matching byte-to-byte to the source file. What is the most likely cause of this problem?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 163,
    'options': ['A. Use SELECT IF.(date >= YYYY-MM-DD AND date <= YYYY-MM-DD',
    'B. Use the WHERE_PARTITIONTIME pseudo column',
    'C. Use the TABLE_DATE_RANGE function',
    'D. Use WHERE date BETWEEN YYYY-MM-DD AND YYYY-MM-DD'],
    'question': 'You have enabled the free integration between Firebase Analytics and Google BigQuery. Firebase now automatically creates a new table daily in BigQuery in the format app_events_YYYYMMDD. You want to query all of the tables for the past 30 days in legacy SQL. What should you do?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 164,
    'options': ['A. Use BigQuery Data Transfer Service to transfer the offsite backup files to a Cloud Storage Multi- Regional storage bucket as a final destination.',
    'B. Use Storage Transfer Service to transfer the offsite backup files to a Cloud Storage Regional bucket as a final destination.',
    'C. Use BigQuery Data Transfer Service to transfer the offsite backup files to a Cloud Storage Regional storage bucket as a final destination.',
    'D. Use Storage Transfer Service to transfer the offsite backup files to a Cloud Storage Multi-Regional storage bucket as a final destination.'],
    'question': 'Your infrastructure includes a set of YouTube channels. You have been tasked with creating a process for sending the YouTube channel data to Google Cloud for analysis. You want to design a solution that allows your world-wide marketing teams to perform ANSI SQL and other types of analysis on up-to-date YouTube channels log data. How should you set up the log data transfer into Google Cloud?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 165,
    'options': ['A. Re-write the application to load accumulated data every 2 minutes.',
    'B. Estimate the average latency for data availability after streaming inserts, and always run queries after waiting twice as long.',
    'C. Convert the streaming insert code to batch load for individual messages.',
    'D. Load the original message to Google Cloud SQL, and export the table every hour to BigQuery via streaming inserts.'],
    'question': 'You need to store and analyze social media postings in Google BigQuery at a rate of 10,000 messages per minute in near real-time. Initially, design the application to use streaming inserts for individual postings. Your application also performs data aggregations right after the streaming inserts. You discover that the queries after streaming inserts do not exhibit strong consistency, and reports from the queries might miss in-flight data. How can you adjust your application design?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 166,
    'options': ['A. Use a service account with the ability to read the batch files and to write to BigQuery',
    'B. Grant the Project Owner role to a service account, and run the job with it',
    'C. Use a user account with the Project Viewer role on the Cloud Dataproc cluster to read the batch files and write to BigQuery',
    'D. Restrict the Google Cloud Storage bucket so only you can see the files'],
    'question': 'You are implementing security best practices on your data pipeline. Currently, you are manually executing jobs as the Project Owner. You want to automate these jobs by taking nightly batch files containing non-public information from Google Cloud Storage, processing them with a Spark Scala job on a Google Cloud Dataproc cluster, and depositing the results into Google BigQuery.,How should you securely run this workload?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 167,
    'options': ['A. Modify the transformMapReduce jobs to apply sensor calibration before they do anything else.',
    'B. Introduce a new MapReduce job to apply sensor calibration to raw data, and ensure all other MapReduce jobs are chained after this.',
    'C. Add sensor calibration data to the output of the ETL process, and document that all users need to apply sensor calibration themselves.',
    'D. Develop an algorithm through simulation to predict variance of data output from the last MapReduce job based on calibration factors, and apply the correction to all data.'],
    'question': 'You architect a system to analyze seismic data. Your extract, transform, and load (ETL) process runs as a series of MapReduce jobs on an Apache Hadoop cluster. The ETL process takes days to process a data set because some steps are computationally expensive. Then you discover that a sensor calibration step hasbeen omitted. How should you change your ETL process to carry out sensor calibration systematically in the future?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 168,
    'options': ['A. Use Cloud Dataprep to find null values in sample source data. Convert all nulls to 0 using a Cloud Dataprep job.',
    'B. Use Cloud Dataflow to find null values in sample source data. Convert all nulls to using a custom script.',
    "C. Use Cloud Dataflow to find null values in sample source data. Convert all nulls to 'none' using a Cloud Dataprep job.",
    "D. Use Cloud Dataprep to find null values in sample source datConvert all nulls to 'none' using a Cloud Dataproc job."],
    'question': 'You are building a data pipeline on Google Cloud. You need to prepare data using a casual method for a machine-learning process. You want to support a logistic regression model. You also need to monitor and adjust for null values, which must remain real-valued and cannot be removed. What should you do?'},
    {'answer': 'ABD',
    'explanation': 'ABD, ',
    'id': 169,
    'options': ['A. Unsupervised learning to determine which transactions are most likely to be fraudulent',
    'B. Clustering to divide the transactions into N categories based on feature similarity.',
    'C. Unsupervised learning to predict the location of a transaction.',
    'D. Supervised learning to predict the location of a transaction.',
    'E. Supervised learning to determine which transactions are most likely to be fraudulent.',
    'F. Reinforcement learning to predict the location of a transaction.'],
    'question': 'Business owners at your company have given you a database of bank transactions. Each row contains the user ID, transaction type, transaction location, and transaction amount. They ask you to investigate what type of machine learning can be applied to the data. Which three machine learning applications can you use? (Choose three.)'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 170,
    'options': ['A. Convert the sharded tables into a single partitioned table',
    'B. Enable query caching so you can cache data from previous months',
    'C. Convert all daily log tables into date-partitioned tables',
    'D. Create separate views to cover each month, and query from these views'],
    'question': 'You launched a new gaming app almost three years ago. You have been uploading log files from the previous day to a separate Google BigQuery table with the table name format LOGS_yyyymmdd. You have been using table wildcard functions to generate daily and monthly reports for all time ranges. Recently you discovered that some queries that cover long date ranges are exceeding the limit of 1000 tables and failing. How can you resolve this issue?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 171,
    'options': ['A. Build and train a classification model with Spark MLlib to generate labels. Build and train a second classification model with Spark MLlib to filter results to match customer preferences. Deploy the models using Cloud Dataproc. Call the models from your application.',
    "B. Build an application that calls the Cloud Video Intelligence API to generate labels. Store data in Cloud Bigtable, and filter the predicted labels to match the user's viewing history to generate preferences.",
    "C. Build an application that calls the Cloud Video Intelligence API to generate labels. Store data in Cloud SQL, and join and filter the predicted labels to match the user's viewing history to generate preferences.",
    'D. Build and train a complex classification model with Spark MLlib to generate labels and filter the results.,Deploy the models using Cloud Dataproc. Call the model from your application.'],
    'question': 'You are developing an application that uses a recommendation engine on Google Cloud. Your solution should display new videos to customers based on past views. Your solution needs to generate labels for the entities in videos that the customer has viewed. Your design must be able to provide very fast filtering suggestions based on data from other customer preferences on several TB of data. What should you do?'},
    {'answer': 'ACD',
    'explanation': 'ACD, ',
    'id': 172,
    'options': ['A. Get more training examples',
    'B. Reduce the number of training examples',
    'C. Use a smaller set of features',
    'D. Increase the regularization parameters ',
    'E. Decrease the regularization parameters',
    'F. Use a larger set of features'],
    'question': 'You are training a spam classifier. You notice that you are overfitting the training data. Which three actions can you take to resolve this problem? (Choose three.)'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 173,
    'options': ['A. Cloud SQL',
    'B. Cloud Datastore',
    'C. Cloud BigTable',
    'D. BigQuery'],
    'question': 'An online retailer has built their current application on Google App Engine. A new initiative at the company mandates that they extend their application to allow their customers to transact directly via the application.They need to manage their shopping transactions and analyze combined data from multiple datasets using a business intelligence (BI) tool. They want to use only a single database for this purpose. Which Google Cloud database should they choose?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 174,
    'options': ['A. Mount the backups to Google Cloud SQL, and then process the data using Google Cloud Dataproc.',
    'B. Connect an on-premises Apache Hadoop cluster to MySQL and perform ETL.',
    'C. Use an ETL tool to load the data from MySQL into Google BigQuery.',
    'D. Add a node to the MySQL cluster and build an OLAP cube there.'],
    'question': "Your company's customer and order databases are often under heavy load. This makes performing analytics against them difficult without harming operations. The databases are in a MySQL cluster, with nightly backups taken using mysqldump. You want to perform analytics with minimal impact on operations. What should you do?"},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 175,
    'options': ['A. Set a single global window to capture all the data.',
    'B. Use watermarks and timestamps to capture the lagged data.',
    'C. Set sliding windows to capture all the lagged data.',
    'D. Ensure every datasource type (stream or batch) has a timestamp, and use the timestamps to define the logic for lagged data.'],
    'question': 'Your company receives both batch- and stream-based event data. You want to process the data using Google Cloud Dataflow over a predictable time period. However, you realize that in some instances data can arrive late or out of order. How should you design your Cloud Dataflow pipeline to handle data that is late or out of order?'},
    {'answer': 'ACE',
    'explanation': 'ACE, ',
    'id': 176,
    'options': ['A. Load data into a different dataset for each client.',
    'B. Load data into different partitions.',
    "C. Restrict a client's dataset to approved users.",
    'D. Only allow a service account to access the datasets.',
    "E. Use the appropriate identity and access management (IAM) roles for each client's users.",
    "F. Put each client's BigQuery dataset into a different table."],
    'question': "Your company handles data processing for a number of different clients. Each client prefers to use their own suite of analytics tools, with some allowing direct query access via Google BigQuery. You need to secure the data so that clients cannot see each other's data. You want to ensure appropriate access to the data. Which three steps should you take? (Choose three.)"},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 177,
    'options': ['A. Disable caching in BigQuery by editing table details',
    'B. Refresh your browser tab showing the visualizations.',
    'C. Clear your browser history for the past hour then reload the tab showing the virtualizations.',
    'D. Disable caching by editing the report settings.'],
    'question': 'You create an important report for your large team in Google Data Studio 360. The report uses Google BigQuery as its data source. You notice that visualizations are not showing data that is less than 1 hour old. What should you do?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 178,
    'options': ['A. Cloud Datastore',
    'B. Cloud SQL',
    'C. Cloud Bigtable',
    'D. BigQuery'],
    'question': 'You want to process payment transactions in a point-of-sale application that will run on Google Cloud Platform. Your user base could grow exponentially, but you do not want to manage infrastructure scaling.Which Google database service should you use?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 179,
    'options': ['A. They have not set the triggers to accommodate the data coming in late, which causes the job to fail',
    'B. They have not applied a non-global windowing function, which causes the job to fail when the pipeline is created',
    'C. They have not assigned the timestamp, which causes the job to fail',
    'D. They have not applied a global windowing function, which causes the job to fail when the pipeline is created'],
    'question': 'Your company is currently setting up data pipelines for their campaign. For all the Google Cloud Pub/Sub streaming data, one of the important business requirements is to be able to periodically identify the inputs and their timings during their campaign. Engineers have decided to use windowing and transformation in Google Cloud Dataflow for this purpose. However, when testing this feature, they find that the Cloud Dataflow job fails for the all streaming insert. What is the most likely cause of this problem?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 180,
    'options': ['A. Create a view CLICK_STREAM_V, where strings from the column DT are cast into TIMESTAMP values. Reference the view CLICK_STREAM_V instead of the table CLICK_STREAM from now on.',
    'B. Add two columns to the table CLICK STREAM: TS of the TIMESTAMP type and IS_NEW of the BOOLEAN type. Reload all data in append mode. For each appended row, set the value of IS_NEW to true. For future queries, reference the column TS instead of the column DT, with the WHERE clause ensuring that the value of IS_NEW must be true.',
    'C. Add a column TS of the TIMESTAMP type to the table CLICK_STREAM, and populate the numeric values from the column TS for each row. Reference the column TS instead of the column DT from now on',
    'D. Construct a query to return every row of the table CLICK_STREAM, while using the built-in function to cast strings from the column DT into TIMESTAMP values. Run the query into a destination table NEW_CLICK_STREAM, in which the column TS is the TIMESTAMP type.Reference the table NEW_CLICK_STREAM instead of the table CLICK_STREAM from now on. In the future, new data is loaded into the table NEW_CLICK_STREAM.',
    'E. Delete the table CLICK_STREAM, and then re-create it such that the column DT is of the TIMESTAMP type. Reload the data.'],
    'question': 'You have spent a few days loading data from comma-separated values (CSV) files into the Google BigQuery table CLICK_STREAM. The column DT stores the epoch time of click events. For convenience, you chose a simple schema where every field is treated as the STRING type. Now, you want to compute web session durations of users who visit your site, and you want to change its data type to the TIMESTAMP. You want to minimize the migration effort without making future queries computationally expensive. What should you do?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 181,
    'options': ['A. Transform text files to compressed Avro using Cloud Dataflow. Use Cloud Storage and BigQuery permanent linked tables for query.',
    'B. Compress text files to gzip using the Grid Computing Tools. Use BigQuery for storage and query.',
    'C. Compress text files to gzip using the Grid Computing Tools. Use Cloud Storage, and then import into Cloud Bigtable for query.',
    'D. Transform text files to compressed Avro using Cloud Dataflow. Use BigQuery for storage and query.'],
    'question': 'You are designing storage for very large text files for a data pipeline on Google Cloud. You want to support ANSI SQL queries. You also want to support compression and parallel load from the input locations using Google recommended practices. What should you do?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 182,
    'options': ['A. Use a sliding time window with a duration of 60 minutes.',
    'B. Use a fixed-time window with a duration of 60 minutes.',
    'C. Use a global window with a time based trigger with a delay of 60 minutes.',
    'D. Use a session window with a gap time duration of 60 minutes.'],
    'question': 'You are designing a basket abandonment system for an ecommerce company. The system will send a message to a user based on these rules:No interaction by the user on the site for 1 hour,Has added more than $30 worth of products to the basket,Has not completed a transaction.You use Google Cloud Dataflow to process the data and decide if a message should be sent. How should you design the pipeline?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 183,
    'options': ['A. Use the Google Cloud Billing API to see what account the warehouse is being billed to.',
    'B. Use Stackdriver Monitoring to see the usage of BigQuery query slots.',
    'C. Get the identity and access management IAM policy of each table',
    'D. Use Google Stackdriver Audit Logs to review data access.'],
    'question': 'Your startup has never implemented a formal security policy. Currently, everyone in the company has access to the datasets stored in Google BigQuery. Teams have freedom to use the service as they see fit, and they have not documented their use cases. You have been asked to secure the data warehouse. You need to discover what everyone is doing. What should you do first?'},
    {'answer': 'DE',
    'explanation': 'DE, ',
    'id': 184,
    'options': ['A. You already have labels for which samples are mutated and which are normal in the database.',
    'B. There are roughly equal occurrences of both normal and mutated samples in the database.',
    'C. You expect future mutations to have different features from the mutated samples in the database',
    'D. There are very few occurrences of mutations relative to normal samples.',
    'E. You expect future mutations to have similar features to the mutated samples in the database.'],
    'question': 'You want to use a database of information about tissue samples to classify future tissue samples as either normal or mutated. You are evaluating an unsupervised anomaly detection method for classifying the tissue samples. Which two characteristic support this method? (Choose two.)'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 185,
    'options': ['A. Redesign the schema to use row keys based on numeric IDs that increase sequentially per user viewing the offers.',
    'B. Redesign the schema to use a single row key to identify values that need to be updated frequently in the cluster.',
    'C. The performance issue should be resolved over time as the site of the BigDate cluster is increased.',
    'D. Redefine the schema by evenly distributing reads and writes across the row space of the table.'],
    'question': 'Your company is running their first dynamic campaign, serving different offers by analyzing real-time data during the holiday season. The data scientists are collecting terabytes of data that rapidly grows every hour during their 30-day campaign. They are using Google Cloud Dataflow to preprocess the data and collect the feature (signals) data that is needed for the machine learning model in Google Cloud Bigtable. The team is observing suboptimal performance with reads and writes of their initial load of 10 TB of data. They want to improve this performance while minimizing cost. What should they do?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 186,
    'options': ['A. Export logs in batch to Google Cloud Storage and then spin up a Google Cloud SQL instance, import the data from Cloud Storage, and run an analysis as needed.',
    'B. Send the data to Cloud Storage and then spin up an Apache Hadoop cluster as needed in Google Cloud Dataproc whenever analysis is required.',
    'C. Send the data to Google Cloud Datastore and then export to BigQuery.',
    'D. Send the data to Google Cloud Pub/Sub, stream Cloud Pub/Sub to Google Cloud Dataflow, and store the data in Google BigQuery.'],
    'question': 'You are deploying 10,000 new Internet of Things devices to collect temperature data in your warehouses globally. You need to process, store and analyze these very large datasets in real time. What should you do?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 187,
    'options': ['A. Use a row key of the form <timestamp>.',
    'B. Use a row key of the form <sensorid>.',
    'C. Use a row key of the form <timestamp>#<sensorid>.',
    'D. Use a row key of the form >#<sensorid>#<timestamp>.'],
    'question': 'Your company is streaming real-time sensor data from their factory floor into Bigtable and they have noticed extremely poor performance. How should the row key be redesigned to improve Bigtable performance on queries that populate real-time dashboards?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 188,
    'options': ['A. Run a local version of Jupiter on the laptop.',
    'B. Host a visualization tool on a VM on Google Compute Engine.',
    'C. Grant the user access to Google Cloud Shell.',
    'D. Deploy Google Cloud Datalab to a virtual machine (VM) on Google Compute Engine.'],
    'question': 'Your company has hired a new data scientist who wants to perform complicated analyses across very large datasets stored in Google Cloud Storage and in a Cassandra cluster on Google Compute Engine. The scientist primarily wants to create labelled data sets for machine learning projects, along with some visualization tasks. She reports that her laptop is not powerful enough to perform her tasks and it is slowing her down. You want to help her perform her tasks. What should you do?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 189,
    'options': ['A. Create encryption keys in Cloud Key Management Service. Reference those keys in your API service calls when accessing the data in your Compute Engine cluster instances.',
    'B. Create encryption keys in Cloud Key Management Service. Use those keys to encrypt your data in all of the Compute Engine cluster instances.',
    'C. Create a dedicated service account, and use encryption at rest to reference your data stored in your Compute Engine cluster instances as part of your API service calls.',
    'D. Create encryption keys locally. Upload your encryption keys to Cloud Key Management Service. Use those keys to encrypt your data in all of the Compute Engine cluster instances.'],
    'question': 'You set up a streaming data insert into a Redis cluster via a Kafka cluster. Both clusters are running on Compute Engine instances. You need to encrypt data at rest with encryption keys that you can create, rotate, and destroy as needed. What should you do?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 190,
    'options': ['A. Update the current pipeline and provide the transform mapping JSON object.',
    'B. Update the current pipeline and use the drain flag.',
    'C. Create a new pipeline that has a new Cloud Pub/Sub subscription and cancel the old pipeline.',
    'D. Create a new pipeline that has the same Cloud Pub/Sub subscription and cancel the old pipeline.'],
    'question': 'You have Google Cloud Dataflow streaming pipeline running with a Google Cloud Pub/Sub subscription as the source. You need to make an update to the code that will make the new Cloud Dataflow pipeline incompatible with the current version. You do not want to lose any data when making this update. What should you do?'},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 191,
    'options': ['A. Store he common data in the HDFS storage for a Google Cloud Dataproc cluster.',
    'B. Store the common data in BigQuery as partitioned tables.',
    'C. Store the common data in BigQuery and expose authorized views.',
    'D. Store the common data encoded as Avro in Google Cloud Storage.'],
    'question': 'Flowlogistic wants to use Google BigQuery as their primary analysis system, but they still have Apache Hadoop and Spark workloads that they cannot move to BigQuery. Flowlogistic does not know how to store the data that is common to both workloads. What should they do?'},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 192,
    'options': ['A. Put the data into Google Cloud Storage.',
    'B. Use preemptible virtual machines (VMs) for the Cloud Dataproc cluster.',
    'C. Migrate some of the cold data into Google Cloud Storage, and keep only the hot data in Persistent Disk.',
    'D. Tune the Cloud Dataproc cluster so that there is just enough disk for all data.'],
    'question': "Your company's on-premises Apache Hadoop servers are approaching end-of-life, and IT has decided to migrate the cluster to Google Cloud Dataproc. A like-for-like migration of the cluster would require 50 TB of Google Persistent Disk per node. The CIO is concerned about the cost of using that much block storage. You want to minimize the storage cost of the migration. What should you do?"},
    {'answer': 'A',
    'explanation': 'A, ',
    'id': 193,
    'options': ['A. Cloud Pub/Sub, Cloud Dataflow, and Cloud Storage',
    'B. Cloud Load Balancing, Cloud Dataflow, and Cloud Storage',
    'C. Cloud Pub/Sub, Cloud SQL, and Cloud Storage',
    'D. Cloud Pub/Sub, Cloud Dataflow, and Local SSD'],
    'question': "Flowlogistic's management has determined that the current Apache Kafka servers cannot handle the data volume for their real-time inventory tracking system. You need to build a new system on Google Cloud Platform (GCP) that will feed the proprietary tracking software. The system must be able to ingest data from a variety of global sources, process and query in real-time, and store the data reliably. Which combination of GCP products should you choose?"},
    {'answer': 'D',
    'explanation': 'D, ',
    'id': 194,
    'options': ['A. Use GROUP BY on the unique ID column and timestamp column and SUM on the values.',
    'B. Use the LAG window function with PARTITION by unique ID along with WHERE LAG IS NOT NULL.',
    'C. Include ORDER BY DESK on timestamp column and LIMIT to 1.',
    'D. Use the ROW_NUMBER window function with PARTITION by unique ID along with WHERE row equals 1.'],
    'question': 'You are building new real-time data warehouse for your company and will use Google BigQuery streaming inserts. There is no guarantee that data will only be sent in once but you do have a unique ID for each row of data and an event timestamp. You want to ensure that duplicates are not included while interactively querying data. Which query type should you use?'},
    {'answer': 'ABF',
    'explanation': 'ABF, ',
    'id': 195,
    'options': ['A. Restrict access to tables by role.',
    'B. Use Google Stackdriver Audit Logging to determine policy violations.',
    'C. Segregate data across multiple tables or databases.',
    'D. Ensure that the data is encrypted at all times.',
    'E. Disable writes to certain tables.',
    'F. Restrict BigQuery API access to approved users.'],
    'question': 'Your company is in a highly regulated industry. One of your requirements is to ensure individual users have access only to the minimum amount of information required to do their jobs. You want to enforce this requirement with Google BigQuery. Which three approaches can you take? (Choose three.)'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 196,
    'options': ['A. The Cloud Pub/Sub topic has too many messages published to it.',
    'B. Your custom endpoint has an out-of-date SSL certificate.',
    'C. Your custom endpoint is not acknowledging messages within the acknowledgement deadline.',
    'D. The message body for the sensor event is too large.'],
    'question': 'You work for a car manufacturer and have set up a data pipeline using Google Cloud Pub/Sub to capture anomalous sensor events. You are using a push subscription in Cloud Pub/Sub that calls a custom HTTPS endpoint that you have created to take action of these anomalous events as they occur. Your custom HTTPS endpoint keeps getting an inordinate amount of duplicate messages. What is the most likely cause of these duplicate messages?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 197,
    'options': ['A. Make a call to the Stackdriver API to list all logs, and apply an advanced filter.',
    'B. Using the Stackdriver API, create a project sink with advanced log filter to export to Pub/Sub, and subscribe to the topic from your monitoring tool.',
    'C. In the Stackdriver logging admin interface, and enable a log sink export to BigQuery.',
    'D. In the Stackdriver logging admin interface, enable a log sink export to Google Cloud Pub/Sub, and subscribe to the topic from your monitoring tool.'],
    'question': 'You want to use Google Stackdriver Logging to monitor Google BigQuery usage. You need an instant notification to be sent to your monitoring tool when new data is appended to a certain table using an insert job, but you do not want to receive notifications for other tables. What should you do?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 198,
    'options': ['A. Use Cloud Dataflow to run your transformations. Monitor the total execution time for a sampling of jobs. Configure the job to use non-default Compute Engine machine types when needed.',
    'B. Use Cloud Dataproc to run your transformations. Use the diagnose command to generate an operational output archive. Locate the bottleneck and adjust cluster resources.',
    'C. Use Cloud Dataflow to run your transformations. Monitor the job system lag with Stackdriver. Use the default autoscaling setting for worker instances.',
    'D. Use Cloud Dataproc to run your transformations. Monitor CPU utilization for the cluster. Resize the number of worker nodes in your cluster via the command line.'],
    'question': 'You are selecting services to write and transform JSON messages from Cloud Pub/Sub to BigQuery for a data pipeline on Google Cloud. You want to minimize service costs. You also want to monitor and accommodate input data volume that will vary in size with minimal manual intervention. What should you do?'},
    {'answer': 'C',
    'explanation': 'C, ',
    'id': 199,
    'options': ['A. Assign global unique identifiers (GUID) to each data entry.',
    'B. Store each data entry as the primary key in a separate database and apply an index.',
    'C. Maintain a database table to store the hash value and other metadata for each data entry.',
    'D. Compute the hash value of each data entry, and compare it with all historical data.'],
    'question': 'Your company uses a proprietary system to send inventory data every 6 hours to a data ingestion service in the cloud. Transmitted data includes a payload of several fields and the timestamp of the transmission. If there are any concerns about a transmission, the system re-transmits the data. How should you deduplicate the data most efficiency?'},
    {'answer': 'B',
    'explanation': 'B, ',
    'id': 200,
    'options': ['A. Import the data in to BigQuery using the gcloud CLI and set max_bad_records to 0.',
    'B. Run a Google Cloud Dataflow batch pipeline to import the data into BigQuery, and push errors to another dead-letter table for analysis.',
    'C. Use federated data sources, and check data in the SQL query.',
    'D. Enable BigQuery monitoring in Google Stackdriver and create an alert.'],
    'question': 'An external customer provides you with a daily dump of data from their database. The data flows into Google Cloud Storage GCS as comma-separated values (CSV) files. You want to analyze this data in Google BigQuery, but the data could have rows that are formatted incorrectly or corrupted. How should you build this pipeline?'} 
=======
        {'answer': 'A',
        'explanation': 'A',
        'id': 1,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Interquartile range (IQR) can be used to identify outliers in a numerical data(True/False)'},
        {'answer': 'A',
        'explanation': 'A, Dimensionality Reduction Techniques is a method to reduce the number of features and is not a Machine Learning Type',
        'id': 2,
        'options': ['A. Dimensionality Reduction Techniques',
        'B. Supervised Machine Learning',
        'C. Reinforcement Learning',
        'D. Unsupervised Machine Learning'],
        'question': 'Which among below is not a machine learning type?'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 3,
        'options': ['A. Cloud Natural Language',
        'B. Cloud Video Intelligence',
        'C. Cloud Translation',
        'D. Cloud Vision'],
        'question': 'Which GCP ML Service can help extract text in a video,including when in the video the text is detected (timestamp) and the location of the text within the frame (bounding box)?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
        'id': 4,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'App Engine Standard environment supports SSH debugging(True/False)'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/dataflow/docs/',
        'id': 5,
        'options': ['A. Apache Beam',
        'B. Apache Nifi',
        'C. Apache Airflow',
        'D. Apache Crunch'],
        'question': 'Cloud Dataflow uses __________ which is a unified programming model that enables one to develop both batch and streaming pipelines'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/bigquery/docs/bigqueryml-intro',
        'id': 6,
        'options': ['A. Principal Component Analysis',
        'B. K means Algorithm',
        'C. Multiclass logistic regression for classification',
        'D. Random Forest'],
        'question': 'BigQuery ML supports which of the following ML models?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/storage-options/',
        'id': 7,
        'options': ['A. Google Cloud Bigtable',
        'B. Google Cloud Datastore',
        'C. Google Cloud Storage',
        'D. Cloud Storage for Firebase'],
        'question': '________ is a scalable, fully-managed NoSQL document database for your web and mobile applications.'},
        {'answer': 'A',
        'explanation': 'A, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 8,
        'options': ['A. Cloud Vision',
        'B. Cloud Natural Language',
        'C. Cloud Video Intelligence',
        'D. Cloud Translation'],
        'question': 'Which GCP ML Service can help to extract text and identify the language from within an image?'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 9,
        'options': ['A. Cloud Vision',
        'B. Cloud Natural Language',
        'C. Cloud Video Intelligence',
        'D. Cloud Translation'],
        'question': 'Which GCP ML Service can help understand the overall sentiment expressed in a block of text?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
        'id': 10,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'With Regards to instance start up time , App Engine Standard environment is faster than App engine Flexible environment(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/composer/',
        'id': 11,
        'options': ['A. Apache Beam',
        'B. Cloud Composer',
        'C. Apache Crunch',
        'D. Apache Nifi'],
        'question': '________ gives you the ability to connect your pipeline through a single orchestration tool whether your workflow lives on-premises, in multiple clouds, or fully within GCP'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/storage/',
        'id': 12,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Google Cloud Storage supports strongly consistent listing(True/False)'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/spanner/docs/audit-logging',
        'id': 13,
        'options': ['A. Data Access (ADMIN_READ)',
        'B. Data Access (DATA_WRITE)',
        'C. Data Access (DATA_READ)',
        'D. User Access(USER_ACCESS)'],
        'question': 'Which among below is not a category of Data Access audit logs for Cloud Spanner?'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 14,
        'options': ['A. Cloud Video Intelligence',
        'B. Cloud Translation',
        'C. Cloud Natural Language',
        'D. Cloud Vision'],
        'question': 'Which GCP ML Service can help detect and translate a document’s language?'},
        {'answer': 'D',
        'explanation': 'D',
        'id': 15,
        'options': ['A. Data Preparation ',
        'B. Modeling Phase',
        'C. Data Understanding',
        'D. Deployment Phase'],
        'question': 'The data mining project manager meets with the production line supervisor to discuss implementation of changes and improvements.Which stage in CRISP-DM does this scenario refer to'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/storage-options/',
        'id': 16,
        'options': ['A. Google Cloud Datastore',
        'B. Google Cloud Bigtable',
        'C. Cloud Storage for Firebase',
        'D. Google Cloud Storage'],
        'question': 'A user wished to store images,videos,objects and blob data in a scalable,fully managed,highly reliable and cost efficient object/blob store.Which GCP storage option is appropriate for this use case?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/best-practices-costs',
        'id': 17,
        'options': ['A. Use a LIMIT clause as a method of cost control',
        'B. Query only the columns that you need.',
        "C. Don't run queries to explore or preview table data.Sample data using preview options",
        'D. Before running queries, preview them to estimate costs.'],
        'question': 'Which among below is not a best practice to control cost in BigQuery?'},
        {'answer': 'C',
        'explanation': 'C, Bianary Dummy Varible helps convert categorical variable into multiple numerical variables',
        'id': 18,
        'options': ['A. Assign numeric values to different levels within a categorical variable and use the numeric values instead',
        'B. Use a classification algorithm instead',
        'C. Convert the categorical variable into binary dummy variables',
        'D. Use the categorical variable as is'],
        'question': 'In order to use categorical variables in a regression problem, which data pre-processing step is needed?'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/dataflow/',
        'id': 19,
        'options': ['A. Dataflow',
        'B. Shell Scripts on Compute Instances',
        'C. Dataproc',
        'D. Cloud SQL'],
        'question': 'Iterative processing and notebooks workloads is recommended to be implemented using which google service?'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/bigquery/docs/bigqueryml-intro',
        'id': 20,
        'options': ['A. Random Forest',
        'B. Naive Bayes',
        'C. Decision Trees',
        'D. Binary logistic regression'],
        'question': 'BigQuery ML supports which of the following ML models?'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 21,
        'options': ['A. Cloud Translation',
        'B. Cloud Video Intelligence',
        'C. Cloud Natural Language',
        'D. Cloud Vision'],
        'question': 'Which GCP ML Service can help track objects within a video?'},
        {'answer': 'D',
        'explanation': 'D',
        'id': 22,
        'options': ['A. To provide a framework for interpretability of the results',
        'B. To reduce the number of predictor items',
        'C. To help ensure that the predictor items are independent',
        'D. To predict a value of a target variable'],
        'question': 'Which of the following is not a goal of Dimensionality Reduction techniques?'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 23,
        'options': ['A. Cloud Video Intelligence',
        'B. Cloud Natural Language',
        'C. Cloud Vision',
        'D. Cloud Translation'],
        'question': 'Which GCP ML Service can help identify entities and label by types such as person, organization, location, events, products, and media from within a text?'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/storage-options/',
        'id': 24,
        'options': ['A. Google Cloud Bigtable',
        'B. Google Cloud Storage',
        'C. Google BigQuery ',
        'D. Google Cloud Datastore'],
        'question': 'A user wishes to generate reports on petabyte scale data using a Business Intelligence (BI) tools.Which storage option provides integration with BI tools and supports OLAP workloads up to petabyte-scale?'},
        {'answer': 'C',
        'explanation': 'C',
        'id': 25,
        'options': ['A. Classification Algorithms',
        'B.  Clustering Algorithms ',
        'C. Assocition Rules ',
        'D.  Principal Component Analysis'],
        'question': 'A professor is conducting a research to examine the proportion of children whose parents read to them and who are themselves good readers.Which Machine learning algorithm can he/she apply ?'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/bigquery/docs/transfer-service-overview',
        'id': 26,
        'options': ['A. Google Transfer Appliance',
        'B. Google Big Data Service',
        'C. Storage Transfer Service',
        'D. BigQuery Data Transfer Service'],
        'question': 'An organisation wishes to automate data movement from Software as a Service (SaaS) applications such as Google Ads and Google Ad Manager on a scheduled, managed basis.This data is further needed to generate reports'},
        {'answer': 'A',
        'explanation': 'A, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 27,
        'options': ['A. Cloud Video Intelligence',
        'B. Cloud Natural Language',
        'C. Cloud Translation',
        'D. Cloud Vision'],
        'question': 'Which GCP ML Service can help detect adult content within a video?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/pubsub/',
        'id': 28,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Cloud Pub/Sub is a HIPAA-compliant service, offering fine-grained access controls and end-to-end encryption(Tre/False)'},
        {'answer': 'D',
        'explanation': 'D',
        'id': 29,
        'options': ['A. Business Understanding,Data Understanding,Data Preparation ,Modeling Phase,Evaluation Phase',
        'B. Data Understanding,Data Preparation ,Modeling Phase,Evaluation Phase,Deployment Phase',
        'C. Modeling Phase,Evaluation Phase,Deployment Phase',
        'D. Business Understanding,Data Understanding,Data Preparation ,Modeling Phase,Evaluation Phase,Deployment Phase'],
        'question': 'Which option among below represents all the stages in CRISP-DM Methodology'},
        {'answer': 'C',
        'explanation': 'C',
        'id': 30,
        'options': ['A. treat the numerical value directly as a categorical variable',
        'B. use min-max normalization',
        'C. Bin the numerical variable into different categories',
        'D. use mean as a reprsentative value'],
        'question': 'To convert a continuous variable into a categorical variable , which of the following technique can we use?'},
        {'answer': 'A',
        'explanation': 'A, Principal components are orthogonal and independent',
        'id': 31,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Selecting suitable principal components from Principal Component Analysis can help avoid multicollinearity in regression problems (True / False)'},
        {'answer': 'C',
        'explanation': 'C',
        'id': 32,
        'options': ['A. Assocition Rules',
        'B. Neural Networks',
        'C. Factor Analysis',
        'D. Linear Regression'],
        'question': 'Which of the following is a Dimensionality Reduction Method?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/storage/',
        'id': 33,
        'options': ['A. Multi Regional',
        'B. Nearline',
        'C. Coldline',
        'D. Regional'],
        'question': '________ Google Cloud Storage is optimized for fast , highly durable storage for data accessed less than once a month'},
        {'answer': 'B',
        'explanation': 'B',
        'id': 34,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'Z-SCORE Standardization is one of the techniques to normalize numeric variables before applying a machine learning model(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/storage-options/',
        'id': 35,
        'options': ['A. Google Cloud Storage',
        'B. Google Cloud Spanner',
        'C. Google Cloud Datastore',
        'D. Google Cloud Bigtable'],
        'question': 'A financial organisation wishes to develop a glocal application to store transactions happening from different part of the world . The storage system must provide low latency transaction support and horizontal scaling.Which GCP service is appropriate for this use case?'},
        {'answer': 'D',
        'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 36,
        'options': ['A. Cloud Video Intelligence',
        'B. Cloud Vision',
        'C. Cloud Translation',
        'D. Cloud Natural Language'],
        'question': 'Which GCP ML Service can help extract tokens and sentences ,identify parts of speech (PoS), and create dependency parse trees for each sentence within a text?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/datastore/',
        'id': 37,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Cloud Datastore supports ACID transactions,SQL-like queries and indexes(True/False)'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
        'id': 38,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'App Engine Flexible environment supports SSH debugging(True/False)'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/bigqueryml-intro',
        'id': 39,
        'options': ['A. Linear Regression',
        'B. Decision Trees',
        'C. Random Forest',
        'D. Neural Networks'],
        'question': 'BigQuery ML supports which of the following ML models?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
        'id': 40,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'App Engine Flexible environment supports running background processes(True/False)'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 41,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Cross Validation is a technique for insuring that the results uncovered in an analysis are generalizable to an independent,unseen,data set(True/False)'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/pubsub/',
        'id': 42,
        'options': ['A. Cloud SQL',
        'B. Google BigTable',
        'C. Dataflow',
        'D. Google BigQuery'],
        'question': 'Which service in combination with Cloud Pub/Sub can be used to implement exactly once processing of incoming stream messages?'},
        {'answer': 'A',
        'explanation': 'A, Confusion Matrix is used to evaluate classification models',
        'id': 43,
        'options': ['A. Confusion Matrix',
        'B. Root Mean Squared Error (RMSE)',
        'C. Coefficient of Determination (R Square)',
        'D. Mean Absolute Error (MAE)'],
        'question': 'Which of the below measures is not used to evaluate regression models'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/compute/docs/faq',
        'id': 44,
        'options': ['A. Both 1 and 2',
        'B. No , we cannot attach to more than 1 instance',
        'C. Yes if the disk is in read-write mode',
        'D. Yes if the disk is in read-only mode'],
        'question': 'Can we attach a persistent disk to more than one GCP compute instance?'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/bigquery/docs/transfer-service-overview',
        'id': 45,
        'options': ['A. Google Ad Manager',
        'B. Campaign Manager',
        'C. On Premise Oracle Database',
        'D. Google Ads'],
        'question': 'Which of the following is not a supported data source for BigQuery Data Transfer Service'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/dataflow/',
        'id': 46,
        'options': ['A. Dataproc',
        'B. Shell Scripts on Compute Instances',
        'C. Cloud SQL',
        'D. Dataflow'],
        'question': 'A startup wishes to use a data processing platform which supports both batch and streaming applications and they would prefer to have a hands-off/serverless data processing platform.Which GCP service is suited for this'},
        {'answer': 'C',
        'explanation': 'C, Association rules can help create rules on which items are brought together',
        'id': 47,
        'options': ['A. Logistic Regression',
        'B. Principal Component Analysis',
        'C. Association Rules',
        'D. Random Forests'],
        'question': 'A retailer wishes to identify the products which are bought together. Given a dataset containing a customer id, receipt id and the products bought. Which type of Machine Learning algorithm is suited to achieve this?'},
        {'answer': 'D',
        'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 48,
        'options': ['A. phone_call',
        'B. command_and_search',
        'C. default',
        'D. video'],
        'question': 'Which model within Cloud Speech-to-Text API is best for audio that originated from video or includes multiple speakers(typically recorded at an 16khz or higher sampling rate)?'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/dataflow/',
        'id': 49,
        'options': ['A. Cloud SQL',
        'B. Dataflow',
        'C. Dataproc',
        'D. Shell Scripts on Compute Instances'],
        'question': 'Machine learning with Spark ML workloads is recommended to be implemented using which google service?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/memorystore/',
        'id': 50,
        'options': ['A. Cloud Storage for Firebase',
        'B. Cloud Memorystore',
        'C. Google Cloud Storage',
        'D. Google Cloud Datastore'],
        'question': '_______ is a fully-managed in-memory data store service for Redis'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/sql/docs/features',
        'id': 51,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Cloud SQL MySQL Instane supports user defined functions(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/solutions/running-janusgraph-with-bigtable',
        'id': 52,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'JanusGraph a Graph Database can use Cloud BigTable as an underlying storage layer(True/False)'},
        {'answer': 'D',
        'explanation': 'D, Logistic regression can be used to create a classification model in this case',
        'id': 53,
        'options': ['A. Linear Regression',
        'B. Principal Component Analysis',
        'C. Association Rules',
        'D. Logistic Regression'],
        'question': 'A bank wishes to predict that a given loan application will default in future. Given a dataset containing customer demographic information, loan application information, credit score and saving balance account information and a label containing default indicator (Y – Will Default, N – Will Not Default). Which type of Machine Learning algorithm is suited to achieve this?'},
        {'answer': 'C',
        'explanation': 'C, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 54,
        'options': ['A. Cloud Vision',
        'B. Cloud Natural Language',
        'C. Cloud Video Intelligence',
        'D. Cloud Translation'],
        'question': 'Which GCP ML Service can help detect scene changes within a video?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/functions/',
        'id': 55,
        'options': ['A. Cloud Translation',
        'B. Google Cloud Functions',
        'C. Google App Engine',
        'D. Google Compute Engine'],
        'question': '_________is a lightweight compute solution for developers to create single-purpose, stand-alone functions that respond to Cloud events without the need to manage a server or runtime environment.'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/sql/docs/features',
        'id': 56,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Cloud SQL PostgreSQL Instane supports Point-in-time recovery (PITR) (True/False)'},
        {'answer': 'A',
        'explanation': 'A, Clusters identifed can be used as a proxy for multiple features',
        'id': 57,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'A Clustering algorithm can be used as a dimension-reduction tool when a dataset has hundred of attributes(True/False)'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 58,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'In a normal probability plot, if the distribution is normal ,the bulk of the points in the plot should fall on a straight lineTrue/False)'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/dataprep/docs/',
        'id': 59,
        'options': ['A. Cloud Dataprep',
        'B. Apache Nifi',
        'C. Data Studio',
        'D. Cloud SQL'],
        'question': '_______ is used to explore and transform raw data from disparate and/or large datasets into clean and structured data for further analysis and processing.'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/bigqueryml-intro',
        'id': 60,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'BigQuery ML functionality is available by using an external tool such as a Jupyter notebook or business intelligence platform(True/False)'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/dataflow/',
        'id': 61,
        'options': ['A. Shell Scripts on Compute Instances',
        'B. Dataproc',
        'C. Dataflow',
        'D. Cloud SQL'],
        'question': 'Data preprocessing for machine learning workloads is recommended to be implemented using which google service?'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 62,
        'options': ['A. Yes', 'B. No'],
        'question': 'A transaction id uniquely identifies a transaction is present in a dataset .The dataset is used to predict whether the transaction is fraudulent or not . Can we safely remove transaction id while training a machine learning model(Yes/No)?'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 63,
        'options': ['A. Cloud Natural Language',
        'B. Cloud Vision',
        'C. Cloud Translation',
        'D. Cloud Video Intelligence'],
        'question': 'Which GCP ML Service can help detect explicit content like adult content or violent content within an image?'},
        {'answer': 'C',
        'explanation': 'C, Clustering algorithms can be used to identify clusters in a data set',
        'id': 64,
        'options': ['A. Association Rules',
        'B. Random Forests',
        'C. Clustering Algorithms',
        'D. Recommendation Algorithms'],
        'question': 'Given a dataset containing customer demographic information and purchase history, we need to segment the customers into multiple segments. Which type of Machine Learning algorithm is suited to achieve this?'},
        {'answer': 'D',
        'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 65,
        'options': ['A. video',
        'B. default',
        'C. command_and_search',
        'D. phone_call'],
        'question': 'Which model within Cloud Speech-to-Text API is best for for audio that originated from a phone call (typically recorded at an 8khz sampling rate)?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/storage-options/',
        'id': 66,
        'options': ['A. Google Cloud Bigtable',
        'B. Google Cloud Datastore',
        'C. Google Cloud Storage',
        'D. Google BigQuery '],
        'question': 'A user wishes to store structured data for high-throughput analytics use case.The storage solution must also provide Low-latency read/write access.Which storage option is appropriate for this use case?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/storage-options/',
        'id': 67,
        'options': ['A. Google BigQuery ',
        'B. Google Cloud Storage',
        'C. Google Cloud Datastore',
        'D. Google Cloud Bigtable'],
        'question': 'Which GCP service provides a scalable, fully-managed Enterprise Data Warehouse (EDW) with SQL and fast response times?'},
        {'answer': 'C',
        'explanation': 'C, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 68,
        'options': ['A. Cloud Natural Language',
        'B. Cloud Translation',
        'C. Cloud Vision',
        'D. Cloud Video Intelligence'],
        'question': 'Which GCP ML Service can help detect popular product logos within an image?'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/storage-options/',
        'id': 69,
        'options': ['A. Google Cloud Storage',
        'B. Google Cloud Bigtable',
        'C. Google Cloud Spanner',
        'D. Google Cloud Datastore'],
        'question': 'Which GCP service provides mission-critical, relational database service with transactional consistency, global scale and high availability?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/dataflow/docs/',
        'id': 70,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Cloud Dataflow can be used to deploy both batch and streaming data processing pipelines(True/False)'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
        'id': 71,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'App Engine Standard environment supports installing third-party binaries(True/False)'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/storage-options/',
        'id': 72,
        'options': ['A. Google Cloud SQL',
        'B. Google Cloud Storage',
        'C. Google Cloud Datastore',
        'D. Google Cloud Bigtable'],
        'question': 'A user wishes to develop an application which caters to operational aspects of the business.For this,he needs an OLTP system to store the data.Which GCP service is appropriate for this use?'},
        {'answer': 'A',
        'explanation': 'A, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 73,
        'options': ['A. Cloud Vision',
        'B. Cloud Natural Language',
        'C. Cloud Video Intelligence',
        'D. Cloud Translation'],
        'question': 'Which GCP ML Service can help detect multiple faces within an image, along with the associated key facial attributes like emotional state or wearing headwear?'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 74,
        'options': ['A. Cloud Video Intelligence',
        'B. Cloud Natural Language',
        'C. Cloud Vision',
        'D. Cloud Translation'],
        'question': 'Which GCP ML Service can help classify text documents in 700+ predefined categories?'},
        {'answer': 'B',
        'explanation': 'B',
        'id': 75,
        'options': ['A. Data Preparation ',
        'B. Data Understanding',
        'C. Evaluation Phase',
        'D. Modeling Phase'],
        'question': 'The data mining project manager meets with the data warehousing manager to discuss how the data will be collected.Which stage in CRISP-DM does this scenario refer to'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/composer/docs/',
        'id': 76,
        'options': ['A. Apache Airflow',
        'B. Apache Beam',
        'C. Apache Nifi',
        'D. Apache Crunch'],
        'question': 'Cloud Composer is a managed __________ service that helps you create, schedule, monitor and manage workflows'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/storage/',
        'id': 77,
        'options': ['A. Regional',
        'B. Multi Regional',
        'C. Coldline',
        'D. Nearline'],
        'question': '________ Google Cloud Storage is optimized for geo redundancy and end user latency'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/compute/docs/faq',
        'id': 78,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'A service account is a Google account that represents an end user(True/False)'},
        {'answer': 'B',
        'explanation': 'B',
        'id': 79,
        'options': ['A. Modeling Phase',
        'B. Evaluation Phase',
        'C. Data Preparation ',
        'D. Data Understanding'],
        'question': 'Managers want to know by next week whether deployment will take place.Therefore,analysts meet to discuss how useful and accurate their model is . Which stage in CRISP-DM does this scenario refer to'},
        {'answer': 'C',
        'explanation': 'C, Coefficient of Determination (R Square) is used to evaluate regression models',
        'id': 80,
        'options': ['A. Area Under the Curve (AUC)',
        'B. ROC Chart',
        'C. Coefficient of Determination (R Square)',
        'D. Confusion Matrix'],
        'question': 'Which of the below technique is not used to evaluate classification models'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/spanner/docs/bulk-loading',
        'id': 81,
        'options': ['A. Upload data before creating secondary indexes',
        'B. Commit between 1 MB to 5 MB mutations at a time',
        'C. Partition your data by primary key',
        'D. Sequentially add all rows in primary key order'],
        'question': 'Which among below is an inefficient practice while loading data in Cloud Spanner?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
        'id': 82,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'App Engine Standard environment supports running background processes(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 83,
        'options': ['A. Cloud Translation',
        'B. Cloud Vision',
        'C. Cloud Natural Language',
        'D. Cloud Video Intelligence'],
        'question': 'Which GCP ML Service can help search the internet for similar images?'},
        {'answer': 'D',
        'explanation': 'D',
        'id': 84,
        'options': ['A. Data Preparation ',
        'B. Modeling Phase',
        'C. Data Understanding',
        'D. Business Understanding'],
        'question': 'The data mining consultant meets with the vice president for marketing,who says that he would like to move forward with customer relationship management.Which stage in CRISP-DM does this scenario refer to'},
        {'answer': 'A',
        'explanation': 'A, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 85,
        'options': ['A. Cloud Vision',
        'B. Cloud Natural Language',
        'C. Cloud Translation',
        'D. Cloud Video Intelligence'],
        'question': 'Which GCP ML Service can help detect broad sets of categories within an image, ranging from modes of transportation to animals?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/datalab/',
        'id': 86,
        'options': ['A. Dataflow', 'B. Datalab', 'C. Dataproc', 'D. Cloud SQL'],
        'question': '_________ provides a managed Jupyter notebook environment to provide interactive tool for data exploration, analysis, visualization and machine learning'},
        {'answer': 'D',
        'explanation': 'D, Multiple Regression problem as there are multiple features',
        'id': 87,
        'options': ['A. Principal Component Analysis',
        'B. \tSimple Linear Regression Algorithm',
        'C. Naïve Bayes Algorithm',
        'D. Multiple Linear Regression Algorithm'],
        'question': 'Given a dataset containing house attributes and the neighbourhood and locality information and the house price, a realtor wishes to set an appropriate price for a new house. Which type of Machine Learning Algorithm can help achieve this.'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/pubsub/docs/',
        'id': 88,
        'options': ['A. Cloud Pub/Sub', 'B. Dataflow', 'C. Dataproc', 'D. Datalab'],
        'question': '_________ is a fully-managed real-time messaging service that allows you to send and receive messages between independent applications.'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/storage/',
        'id': 89,
        'options': ['A. Coldline',
        'B. Multi Regional',
        'C. Regional',
        'D. Nearline'],
        'question': '________ Google Cloud Storage is optimized for high performance local access.Eg: Whenyou need to support high frequency analytics workload'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/kubernetes-engine/',
        'id': 90,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Google Kubernetes engine provides stateful application support.One can attach persistent storage to containers, and even host complete databases(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/storage-options/',
        'id': 91,
        'options': ['A. Cloud Storage for Firebase',
        'B. Firebase Realtime Database ',
        'C. Google Cloud Datastore',
        'D. Google Cloud Storage'],
        'question': '________ is a realtime ,NoSQL JSON database for developing web and mobile applications.'},
        {'answer': 'D',
        'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 92,
        'options': ['A. video',
        'B. default',
        'C. phone_call',
        'D. command_and_search'],
        'question': 'Which model within Cloud Speech-to-Text API is best for short queries such as voice commands or voice search?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/storage-transfer/docs/',
        'id': 93,
        'options': ['A. Google Transfer Appliance',
        'B. Storage Transfer Service',
        'C. Google Big Data Service',
        'D. BigQuery Data Transfer Service'],
        'question': 'An organisation wishes to move their Online Analytics Data to GCP Cloud Storage.Which service can it use?'},
        {'answer': 'B',
        'explanation': 'B, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 94,
        'options': ['A. Cloud Natural Language',
        'B. Dialogflow',
        'C. Cloud Vision',
        'D. Cloud Video Intelligence'],
        'question': 'Which GCP Service makes it easy for one to design and integrate a conversational user interface into a mobile app, web application, device, bot, interactive voice response systems, and so on?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/solutions/opentsdb-cloud-platform',
        'id': 95,
        'options': ['A. Google Cloud Storage',
        'B. Google Cloud Bigtable',
        'C. Cloud Storage for Firebase',
        'D. Google Cloud Datastore'],
        'question': 'OpenTSDB can be used to monitor Time-Series Data using which of the below GCP storage service'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/gis-visualize',
        'id': 96,
        'options': ['A. Data Studio',
        'B. Jupyter notebooks ',
        'C. BigQuery Geo Viz',
        'D. Google Earth Engine'],
        'question': 'BigQuery GIS data cannot be currently visualized using ?'},
        {'answer': 'D',
        'explanation': 'D, It is based on definition of Reinforcement learning',
        'id': 97,
        'options': ['A. Unsupervised Machine Learning',
        'B. Supervised Machine Learning',
        'C. Dimensionality Reduction Techniques',
        'D. Reinforcement Learning'],
        'question': '___________ is a type of Machine Learning which aims to maximum a cumulative measure (say a reward) based on interactions with a given system. Eg : A robotic car needs to figure out a best way to traverse a path . The best way is the one with limited hurdles and shortest path.'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/sql/',
        'id': 98,
        'options': ['A. Oracle', 'B. Teradata', 'C. MySQL', 'D. DB2'],
        'question': 'Cloud SQL supports which of the following database engines?'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 99,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'K Means Clustering can be used to identify groups of numerical variables.These groups can then be used as categorical variables for models which requires categorical variables as an input(True/False)'},
        {'answer': 'B',
        'explanation': 'B',
        'id': 100,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'MIN-MAX Normalization is one of the techniques to normalize numeric variables before applying a machine learning model(True/False)'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/iam/docs/resource-hierarchy-access-control',
        'id': 101,
        'options': ['A. Grant roles at the smallest scope needed. For example, if a user only needs access to publish messages to a Cloud Pub/Sub topic, grant the Publisher role to the user for that topic.',
        'B. Use the security principle of least privilege to grant Cloud IAM roles; that is, only give the least amount of access necessary to your resources.',
        'C. Use projects to group resources that share the same trust boundary. For example, resources for the same product or microservice can belong to the same project.',
        'D. Grant roles to individual members instead of to a Google group when possible'],
        'question': 'Which of the below is not a best practice for setting Cloud IAM roles?'},
        {'answer': 'D',
        'explanation': 'D',
        'id': 102,
        'options': ['A. modified', 'B. synchronize', 'C. upsert', 'D. update'],
        'question': 'Hadoop distcp command can be used to synchronize the target directory with the updated files in the source directory.Which option in distcp can be used to achive this?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/dataflow/',
        'id': 103,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'Cloud Dataflow supports reliable & consistent Exactly-once Processing(True/False)'},
        {'answer': 'B',
        'explanation': 'B, The combiner function helps to cut down the amount of data shuffled between the mappers and reducers and is not a replacement for a reducer function',
        'id': 104,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'A combiner function is a replacement for a reducer function(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/bigquery-connector-for-excel',
        'id': 105,
        'options': ['A. Excel GCP Addin',
        'B. BigQuery Connector for Excel',
        'C. Excel BigQuery Integrator',
        'D. Excel VBA Programming'],
        'question': 'Excel can be used to analyze data in BigQuery using which of the following tools?'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 106,
        'options': ['A. balancer', 'B. suffler', 'C. distcp', 'D. datamover'],
        'question': '_______ program is a Hadoop daemon that redistributes blocks by moving them from overutilized datanodes to underutlized datanodes,while adhering to the block replica placement policy that makes data loss unlikely by placing block replicas on different racks'},
        {'answer': 'D',
        'explanation': 'D',
        'id': 107,
        'options': ['A. Data Understanding',
        'B. Model Evaluation',
        'C. Data Preparation ',
        'D. Modeling Phase'],
        'question': 'The analysts meet to discuss whether the neural network or decision tree models should be applied.Which stage in CRISP-DM does this scenario refer to'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/bigquery/external-data-sources',
        'id': 108,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'Data strored in Parquet or ORC format in Cloud Storage can be queried using BigQuery(True/False)'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/trace/docs/',
        'id': 109,
        'options': ['A. Stackdriver Logging',
        'B. Stackdriver Debugger',
        'C. Stackdriver Trace',
        'D. Stackdriver Error Reporting'],
        'question': 'An application developer sees some latency issues in an application running on Google App Engine.Which GCP Service can he use to trace and colllect latency data for further analysis?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/views-intro',
        'id': 110,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'BigQuery views are materialised views and are not logical views(True/False)'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 111,
        'options': ['A. CLUSTERED BY',
        'B. SUBGROUP BY',
        'C. PARTION BY',
        'D. BUCKET BY'],
        'question': 'Which Clause in HiveQL can be used to specify Bucketted Columns at the time of table creation?'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 112,
        'options': ['A. HDFS Federation',
        'B. Hadoop Streaming',
        'C. HDFS High Availability',
        'D. Hadoop Batch'],
        'question': 'Hadoop provides a feature whih allows a cluster to scale by adding namenodes,each of which manages a portion of the filesystem namespace.Eg : one namenode might manage all the files rooted under /user,say,and a second namenode might handle files under /share.This feature is termed as ?'},
        {'answer': 'B',
        'explanation': 'B',
        'id': 113,
        'options': ['A. Apache Flume',
        'B. Apache Pig',
        'C. Apache Sqoop',
        'D. Apache Hive'],
        'question': '_______ is a scripting and data flow programming language to explore large datasets'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/bigquery/external-data-sources',
        'id': 114,
        'options': ['A. Stackdriver',
        'B. CloudSQL',
        'C. Cloud Spanner',
        'D. Google Cloud Bigtable'],
        'question': 'BigQuery offers support for querying data directly from ?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/debugger/',
        'id': 115,
        'options': ['A. Stackdriver Monitoring',
        'B. Stackdriver Error Reporting',
        'C. Stackdriver Logging',
        'D. Stackdriver Debugger'],
        'question': '_______ aggregates and displays errors produced in your running cloud services.'},
        {'answer': 'A',
        'explanation': 'A, Map outputs are intermediate outputs to be consumed by reducer to generate final outputs.Storing intermediate outputs in HDFS would be an overkill due to HDFS replication',
        'id': 116,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Map tasks write their output to the local disk and not to HDFS(True/False)'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 117,
        'options': ['A. distcp', 'B. distcopy', 'C. cp', 'D. copy'],
        'question': 'Hadoop comes with a program called _______ for copying data to and from Hadoop filesystems in parallel'},
        {'answer': 'A',
        'explanation': 'A, The input to a single reduce task is normally the output from multiple mappers',
        'id': 118,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': "Reduce tasks don't have the advantage of data locality(True/False)"},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
        'id': 119,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'App Engine Standard environment supports writing to local disk(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/iam/docs/resource-hierarchy-access-control',
        'id': 120,
        'options': ['A. Both Bob and Alice have editor and publisher role on topic_new',
        'B. Bob will have editor role on topic_new.Alice will have publisher role on topic_new',
        'C. Bob will not have any role on topic_new.Alice will not have publisher role on topic_new',
        'D. Bob will have editor role on topic_new.Alice will not have any role on topic_new'],
        'question': 'In Cloud Pub/Sub, topics and subscriptions are resources that live under a project. Assume that project_new has a topic topic_new under it. If you set a policy on project_new that grants the editor role to bob@gmail.com, and set a policy on topic_new that grants the publisher role to alice@gmail.com,then which of the following statement is true'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/bigquery/docs/querying-clustered-tables',
        'id': 121,
        'options': ['A. Do not compare clustered columns to other columns',
        "B. Filter clustered columns in the order they're specified",
        'C. Comparing clustered columns with other columns in the where clause will not impact performance',
        'D. Do not use clustered columns in complex filter expressions'],
        'question': 'Which of the following is not recommended to obtain best performance from queries against clustered tables in BigQuery?'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/bigquery/docs/saving-sharing-queries',
        'id': 122,
        'options': ['A. Private',
        'B. Project-level',
        'C. Orgabization-level',
        'D. Public'],
        'question': 'Queries in BigQuery can be saved or shared with others . Which of the below is not a type of saved queries?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/bigquery/quotas#streaming_inserts',
        'id': 123,
        'options': ['A. App Engine , BigQuery Streaming inserts , DataStudio for Visualization',
        'B. App Engine , Data FLow , Jupyter Notebook',
        'C. Compute Engine , Big Query Batch Inserts , Data Studio',
        'D. App Engine , Data Proc , Jupyter Notebook'],
        'question': 'An organisation wishes to enable real time analytics on user interactions on their web application . They estimate that there will be 1000 interactions per second and wishes to use services which are ops free.Which combination of services can be used in this case?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/cached-results',
        'id': 124,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'BigQuery Query Results will not be cached when your query runs against an external data source(True/False)'},
        {'answer': 'A',
        'explanation': 'A, Because it males reading records a non local operation and so it is not recommended for Hadoop',
        'id': 125,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Storing data in a normalized format is usually not recommended for Hadoop (True/False)'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/dataflow/',
        'id': 126,
        'options': ['A. Shell Scripts on Compute Instances',
        'B. Cloud SQL',
        'C. Dataflow',
        'D. Dataproc'],
        'question': 'An orgainisation wishes to move their existing map reduce jobs from on premise to a cloud environment.Which GCP service is suited for this?'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/filestore/docs/',
        'id': 127,
        'options': ['A. Cloud Storage',
        'B. Cloud SQL',
        'C. Cloud Filestore',
        'D. Cloud BigTable'],
        'question': '________ provides a fully managed NFS file servers on Google Cloud Platform (GCP) for use with applications running on Compute Engine virtual machines (VMs) instances or Kubernetes Engine clusters.'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/access-control',
        'id': 128,
        'options': ['A. jobUser', 'B. dataOwner', 'C. user', 'D. dataViewer'],
        'question': 'A BigQuery Administrator wishes to grant a user the priviledge to create jobs/queries and an ability to cancel self submitted jobs.Which role can he assign to the user?'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://www.tensorflow.org/guide/',
        'id': 129,
        'options': ['A. Estimators',
        'B. Importing Data',
        'C. Eager Execution',
        'D. Keras'],
        'question': "_______ is a TensorFlow's high-level API for building and training deep learning models."},
        {'answer': 'B',
        'explanation': 'B',
        'id': 130,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'Z-SCORE can be used to identify outliers in a numerical data(True/False)'},
        {'answer': 'C',
        'explanation': 'C',
        'id': 131,
        'options': ['A. Hadoop Connector',
        'B. Hadoop Interface Programming',
        'C. Hadoop Streaming',
        'D. Hadoop Batch'],
        'question': 'Hadoop provides an API to MapReduce that allows you to write your map and reduce functions in languages other than Java.This feature is termed as ?'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/bigquery/docs/querying-wildcard-tables',
        'id': 132,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'In BigQuery,Wildcard tables support native BigQuery storage only. You cannot use wildcards when querying an external table or a view.(True/False)'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/transfer-appliance/docs/2.0/',
        'id': 133,
        'options': ['A. BigQuery Data Transfer Service',
        'B. Storage Transfer Service',
        'C. Google Transfer Appliance',
        'D. Google Big Data Service'],
        'question': 'An organisation wishes to move their Analytics Data from on premise storage to GCP Cloud Storage.Which service can it use?'},
        {'answer': 'D',
        'explanation': 'D, Please refer GCP ML Services Documentation https://cloud.google.com/products/ai/',
        'id': 134,
        'options': ['A. Cloud Video Intelligence',
        'B. Cloud Natural Language',
        'C. Cloud Translation',
        'D. Cloud Vision'],
        'question': 'Which GCP ML Service can help detect popular natural and man-made structures within an image?'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/debugger/',
        'id': 135,
        'options': ['A. Stackdriver Logging',
        'B. Stackdriver Monitoring',
        'C. Stackdriver Error Reporting',
        'D. Stackdriver Debugger'],
        'question': '_______ is a feature of the Google Cloud Platform that lets you inspect the state of a running application, in real time, without stopping or slowing it down.'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 136,
        'options': ['A. Data Locality',
        'B. Distributed Computing',
        'C. Cloud Computing',
        'D. Rack Awareness'],
        'question': 'Hadoop does its best to run the map task on a node where the input data resides in HDFS.This optimization technique is referred to as?'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/iam/docs/testing-permissions',
        'id': 137,
        'options': ['A. EvaluateIamPermissions()',
        'B. CheckIamPermissions()',
        'C. testIamPermissions()',
        'D. getIamPermissions()'],
        'question': '_______ allows you to test Cloud IAM permissions on a user for a resource.'},
        {'answer': 'B',
        'explanation': 'B',
        'id': 138,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'When you drop an External Table , Hive will leave the data untouched and only delete the metadata(True/False)'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 139,
        'options': ['A. No', 'B. Yes'],
        'question': 'A dataset containing fields (Gender,Age,Occuption,Earnings) has a contant value for field Occupation (say Software Engineer).A classification algorithm to predict the Earnings has an accuracy of 78% . If we remove the field Occupation to re-build the model , will it change the model accuracy(Yes/No)?'},
        {'answer': 'D',
        'explanation': 'D, Please refer https://cloud.google.com/storage-options/',
        'id': 140,
        'options': ['A. Google Cloud Datastore',
        'B. Google Cloud Storage',
        'C. Google Cloud Bigtable',
        'D. Cloud Storage for Firebase'],
        'question': 'A user wishes to develop a mobile app which will capture unstructured/semi-structured data on user interactions with the mobile app.Which GCP storage option is appropriate for this use case?'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/pubsub/',
        'id': 141,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'Cloud Pub/Sub supports At-least-once delivery of messages(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/storage/',
        'id': 142,
        'options': ['A. Multi Regional',
        'B. Coldline',
        'C. Regional',
        'D. Nearline'],
        'question': '________ Google Cloud Storage is optimized for fast , highly durable storage for data accessed less than once a year'},
        {'answer': 'A',
        'explanation': 'A',
        'id': 143,
        'options': ['A. m', 'B. d', 'C. a', 'D. degree'],
        'question': 'The degree of parallelism (number of mappers) for distcp can be controlled by which argument'},
        {'answer': 'A',
        'explanation': 'A, Please refer https://cloud.google.com/appengine/docs/the-appengine-environments',
        'id': 144,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'App Engine Flexible environment supports writing to local disk(True/False)'},
        {'answer': 'B',
        'explanation': 'B, YARN supports FIFO,Capacity and Fair Schedulers',
        'id': 145,
        'options': ['A. FIFO', 'B. Complexity based', 'C. Capacity', 'D. Fair'],
        'question': 'Which of the below is not a scheduler option provided by YARN?'},
        {'answer': 'C',
        'explanation': 'C',
        'id': 146,
        'options': ['A. Apache Sqoop',
        'B. Apache Flume',
        'C. Apache Hive',
        'D. Apache Pig'],
        'question': '_______ is a framework for data warehousing on top of Hadoop'},
        {'answer': 'B',
        'explanation': 'B, Hive stores table metadata information in a relational database',
        'id': 147,
        'options': ['A. TRUE', 'B. FALSE'],
        'question': 'Hive stores table metadata information in HDFS(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/cached-results',
        'id': 148,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'BigQuery Query Results will not be cached when you are querying multiple tables using a wildcard(True/False)'},
        {'answer': 'B',
        'explanation': 'B, Please refer https://cloud.google.com/bigquery/docs/cached-results',
        'id': 149,
        'options': ['A. FALSE', 'B. TRUE'],
        'question': 'BigQuery Query Results will not be cached when the query uses non-deterministic functions; for example, date and time functions such as CURRENT_TIMESTAMP() and NOW(), and other functions such as CURRENT_USER() return different values depending on when a query is executed(True/False)'},
        {'answer': 'C',
        'explanation': 'C, Please refer https://cloud.google.com/iam/docs/understanding-service-accounts',
        'id': 150,
        'options': ['A. Do not delete service accounts that are in use by running instances on Google App Engine or Google Compute Engine.',
        'B. Use the display name of a service account to keep track of the service accounts. When you create a service account, populate its display name with the purpose of the service account.',
        'C. Avoid rotation of user-managed service account keys',
        'D. Restrict who can act as service accounts. Users who are Service Account Users for a service account can indirectly access all the resources the service account has access to. Therefore, be cautious when granting the serviceAccountUser role to a user.'],
        'question': 'Which of the below is not a best practice with relation to setting up a service account?'},
        {'answer': 'C',
        'explanation': 'C',
        'id': 151,
        'options': ['A. Use Cloud SQL for storage. Use Cloud Dataflow to transform data to support query patterns.',
        'B. Use Cloud SQL for storage. Add secondary indexes to support query patterns.',
        'C. Use Cloud Spanner for storage. Add secondary indexes to support query patterns.',
        'D. Use Cloud Spanner for storage. Use Cloud Dataflow to transform data to support query patterns.'],
        'question': 'You are designing storage for two relational tables that are part of a 10-TB database on Google Cloud. You want to support transactions that scale horizontally. You also want to optimize data for range queries on nonkey columns. What should you do?'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 152,
        'options': ["A. 'bigquery-public-data.noaa_gsod.gsod'*",
        'B. bigquery-public-data.noaa_gsod.gsod*',
        "C. 'bigquery-public-data.noaa_gsod.gsod*`",
        "D. 'bigquery-public-data.noaa_gsod.gsod'"],
        'question': "Your company is using WHILECARD tables to query data across multiple tables with similar names. The SQL statement is currently failing with the following error:# Syntax error : Expected end of statement but got “-“ at [4:11] SELECT age FROM bigquery-public-data.noaa_gsod.gsod WHERE age != 99 AND_TABLE_SUFFIX = '1929' ORDER BY age DESC Which table name will make the SQL statement work correctly?"},
    {'answer': 'C',
        'explanation': 'C',
        'id': 153,
        'options': ['A. Issue a command to restart the database servers.',
        'B. Reduce the query frequency to once every hour until the database comes back online.',
        'C. Retry the query with exponential backoff, up to a cap of 15 minutes.',
        'D. Retry the query every second until it comes back online to minimize staleness of data.'],
        'question': 'Your weather app queries a database every 15 minutes to get the current temperature. The frontend is powered by Google App Engine and server millions of users. How should you design the frontend to respond to a database failure?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 154,
        'options': ['A. Switch Cloud Dataflow to pull messages from Cloud Pub/Sub instead of Cloud Pub/Sub pushing messages to Cloud Dataflow.',
        'B. Check the dashboard application to see if it is not displaying correctly.',
        'C. Use Google Stackdriver Monitoring on Cloud Pub/Sub to find the missing messages.',
        'D. Run a fixed dataset through the Cloud Dataflow pipeline and analyze the output.'],
        'question': 'Your software uses a simple JSON format for all messages. These messages are published to Google Cloud Pub/Sub, then processed with Google Cloud Dataflow to create a real-time dashboard for the CFO. During testing, you notice that some messages are missing in the dashboard. You check the logs, and all messages are being published to Cloud Pub/Sub successfully. What should you do next?'},
    {'answer': 'A',
        'explanation': 'A',
        'id': 155,
        'options': ['A. Use pre-emptible virtual machines (VMs) for the cluster',
        'B. Use SSDs on the worker nodes so that the job can run faster',
        'C. Use a higher-memory node so that the job runs faster',
        'D. Migrate the workload to Google Cloud Dataflow'],
        'question': 'Your analytics team wants to build a simple statistical model to determine which customers are most likely to work with your company again, based on a few different metrics. They want to run the model on Apache Spark, using data housed in Google Cloud Storage, and you have recommended using Google Cloud Dataproc to execute this job. Testing has shown that this workload can run in approximately 30 minutes on a 15-node cluster, outputting the results into Google BigQuery. The plan is to run this workload weekly. How should you optimize the cluster for cost?'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 156,
        'options': ['A.  E. Create a Hadoop cluster on Google Compute Engine that uses Local SSD disks.',
        'B. Create a Google Cloud Dataflow job to process the data.',
        'C. Create a Cloud Dataproc cluster that uses the Google Cloud Storage connector."',
        'D. Create a Google Cloud Dataproc cluster that uses persistent disks for HDFS.',
        'E. Create a Hadoop cluster on Google Compute Engine that uses persistent disks.'],
        'question': 'Your company is migrating their 30-node Apache Hadoop cluster to the cloud. They want to re-use Hadoop jobs they have already created and minimize the management of the cluster as much as possible. They also want to be able to persist data beyond the life of the cluster. What should you do?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 157,
        'options': ["A. Integrate with a single sign-on (SSO) platform, and pass each user's credentials along with the query request",
        'B. Create groups for your users and give those groups access to the dataset',
        'C. Create a dummy user and grant dataset access to that user. Store the username and password for that user in a file on the files system, and use those credentials to access the BigQuery dataset',
        "D. Create a service account and grant dataset access to that account. Use the service account's private key to access the dataset"],
        'question': "You are integrating one of your internal IT applications and Google BigQuery, so users can query BigQuery from the application's interface. You do not want individual users to authenticate to BigQuery and you do not want to give them access to the dataset. You need to securely access BigQuery from your IT application.What should you do?"},
    {'answer': 'D',
        'explanation': 'D',
        'id': 158,
        'options': ['A. Call a transform that returns TableRow objects, where each element in the PCollexction represents a single row in the table.',
        'B. Use of both the Google BigQuery TableSchema and TableFieldSchema classes.',
        'C. Specify the TableReference object in the code.',
        'D. Use .fromQuery operation to read specific fields from the table.'],
        'question': 'Your company is performing data preprocessing for a learning algorithm in Google Cloud Dataflow. Numerous data logs are being are being generated during this step, and the team wants to analyze them. Due to the dynamic nature of the campaign, the data is growing exponentially every hour.The data scientists have written the following code to read the data for a new key features in the logs. BigQueryIO.Read.named(“ReadLogData”).from(“clouddataflow-readonly:samples.log_data”).You want to improve the performance of this data read. What should you do?'},
    {'answer': 'B',
        'explanation': 'B',
        'id': 159,
        'options': ['A. Build and train a text classification model using TensorFlow. Deploy the model using Cloud Machine Learning Engine. Call the model from your application and process the results as labels.',
        'B. Call the Cloud Natural Language API from your application. Process the generated Entity Analysis as labels.',
        'C. Build and train a text classification model using TensorFlow. Deploy the model using a Kubernetes Engine cluster. Call the model from your application and process the results as labels.',
        'D. Call the Cloud Natural Language API from your application. Process the generated Sentiment Analysis as labels.'],
        'question': "You are developing an application on Google Cloud that will automatically generate subject labels for users' blog posts. You are under competitive pressure to add this feature quickly, and you have no additional developer resources. No one on your team has experience with machine learning. What should you do?"},
    {'answer': 'A',
        'explanation': 'A',
        'id': 160,
        'options': ['A. Combine highly co-dependent features into one representative feature.',
        'B. Instead of feeding in each feature individually, average their values in batches of 3.',
        'C. Remove the features that have null values for more than 50% of the training records.',
        'D. Eliminate features that are highly correlated to the output labels.'],
        'question': 'You are building a model to predict whether or not it will rain on a given day. You have thousands of input features and want to see if you can improve training speed by removing some features while having a minimum effect on model accuracy. What can you do?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 161,
        'options': ['A. Use Cloud Bigtable for storage. Link as permanent tables in BigQuery for query.',
        'B. Use Cloud Storage for storage. Link as temporary tables in BigQuery for query.',
        'C. Use Cloud Bigtable for storage. Install the HBase shell on a Compute Engine instance to query the Cloud Bigtable data.',
        'D. Use Cloud Storage for storage. Link as permanent tables in BigQuery for query.'],
        'question': 'You are designing storage for 20 TB of text files as part of deploying a data pipeline on Google Cloud. Your input data is in CSV format. You want to minimize the cost of querying aggregate values for multiple users who will query the data in Cloud Storage with multiple engines. Which storage service and schema design should you use?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 162,
        'options': ['A. The CSV data loaded in BigQuery is not flagged as CSV.',
        'B. The CSV data has invalid rows that were skipped on import.',
        'C. The CSV data has not gone through an ETL phase before loading into BigQuery.',
        "D. The CSV data loaded in BigQuery is not using BigQuery's default encoding."],
        'question': 'Your company is loading comma-separated values (CSV) files into Google BigQuery. The data is fully imported successfully; however, the imported data is not matching byte-to-byte to the source file. What is the most likely cause of this problem?'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 163,
        'options': ['A. Use SELECT IF.(date >= YYYY-MM-DD AND date <= YYYY-MM-DD',
        'B. Use the WHERE_PARTITIONTIME pseudo column',
        'C. Use the TABLE_DATE_RANGE function',
        'D. Use WHERE date BETWEEN YYYY-MM-DD AND YYYY-MM-DD'],
        'question': 'You have enabled the free integration between Firebase Analytics and Google BigQuery. Firebase now automatically creates a new table daily in BigQuery in the format app_events_YYYYMMDD. You want to query all of the tables for the past 30 days in legacy SQL. What should you do?'},
    {'answer': 'A',
        'explanation': 'A',
        'id': 164,
        'options': ['A. Use BigQuery Data Transfer Service to transfer the offsite backup files to a Cloud Storage Multi- Regional storage bucket as a final destination.',
        'B. Use Storage Transfer Service to transfer the offsite backup files to a Cloud Storage Regional bucket as a final destination.',
        'C. Use BigQuery Data Transfer Service to transfer the offsite backup files to a Cloud Storage Regional storage bucket as a final destination.',
        'D. Use Storage Transfer Service to transfer the offsite backup files to a Cloud Storage Multi-Regional storage bucket as a final destination.'],
        'question': 'Your infrastructure includes a set of YouTube channels. You have been tasked with creating a process for sending the YouTube channel data to Google Cloud for analysis. You want to design a solution that allows your world-wide marketing teams to perform ANSI SQL and other types of analysis on up-to-date YouTube channels log data. How should you set up the log data transfer into Google Cloud?'},
    {'answer': 'B',
        'explanation': 'B',
        'id': 165,
        'options': ['A. Re-write the application to load accumulated data every 2 minutes.',
        'B. Estimate the average latency for data availability after streaming inserts, and always run queries after waiting twice as long.',
        'C. Convert the streaming insert code to batch load for individual messages.',
        'D. Load the original message to Google Cloud SQL, and export the table every hour to BigQuery via streaming inserts.'],
        'question': 'You need to store and analyze social media postings in Google BigQuery at a rate of 10,000 messages per minute in near real-time. Initially, design the application to use streaming inserts for individual postings. Your application also performs data aggregations right after the streaming inserts. You discover that the queries after streaming inserts do not exhibit strong consistency, and reports from the queries might miss in-flight data. How can you adjust your application design?'},
    {'answer': 'A',
        'explanation': 'A',
        'id': 166,
        'options': ['A. Use a service account with the ability to read the batch files and to write to BigQuery',
        'B. Grant the Project Owner role to a service account, and run the job with it',
        'C. Use a user account with the Project Viewer role on the Cloud Dataproc cluster to read the batch files and write to BigQuery',
        'D. Restrict the Google Cloud Storage bucket so only you can see the files'],
        'question': 'You are implementing security best practices on your data pipeline. Currently, you are manually executing jobs as the Project Owner. You want to automate these jobs by taking nightly batch files containing non-public information from Google Cloud Storage, processing them with a Spark Scala job on a Google Cloud Dataproc cluster, and depositing the results into Google BigQuery.,How should you securely run this workload?'},
    {'answer': 'A',
        'explanation': 'A',
        'id': 167,
        'options': ['A. Modify the transformMapReduce jobs to apply sensor calibration before they do anything else.',
        'B. Introduce a new MapReduce job to apply sensor calibration to raw data, and ensure all other MapReduce jobs are chained after this.',
        'C. Add sensor calibration data to the output of the ETL process, and document that all users need to apply sensor calibration themselves.',
        'D. Develop an algorithm through simulation to predict variance of data output from the last MapReduce job based on calibration factors, and apply the correction to all data.'],
        'question': 'You architect a system to analyze seismic data. Your extract, transform, and load (ETL) process runs as a series of MapReduce jobs on an Apache Hadoop cluster. The ETL process takes days to process a data set because some steps are computationally expensive. Then you discover that a sensor calibration step hasbeen omitted. How should you change your ETL process to carry out sensor calibration systematically in the future?'},
    {'answer': 'A',
        'explanation': 'A',
        'id': 168,
        'options': ['A. Use Cloud Dataprep to find null values in sample source data. Convert all nulls to 0 using a Cloud Dataprep job.',
        'B. Use Cloud Dataflow to find null values in sample source data. Convert all nulls to using a custom script.',
        "C. Use Cloud Dataflow to find null values in sample source data. Convert all nulls to 'none' using a Cloud Dataprep job.",
        "D. Use Cloud Dataprep to find null values in sample source datConvert all nulls to 'none' using a Cloud Dataproc job."],
        'question': 'You are building a data pipeline on Google Cloud. You need to prepare data using a casual method for a machine-learning process. You want to support a logistic regression model. You also need to monitor and adjust for null values, which must remain real-valued and cannot be removed. What should you do?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 169,
        'options': ['A. Unsupervised learning to determine which transactions are most likely to be fraudulent',
        'B. Clustering to divide the transactions into N categories based on feature similarity.',
        'C. Unsupervised learning to predict the location of a transaction.',
        'D. Supervised learning to predict the location of a transaction.',
        'E. Supervised learning to determine which transactions are most likely to be fraudulent.',
        'F. Reinforcement learning to predict the location of a transaction.'],
        'question': 'Business owners at your company have given you a database of bank transactions. Each row contains the user ID, transaction type, transaction location, and transaction amount. They ask you to investigate what type of machine learning can be applied to the data. Which three machine learning applications can you use? (Choose three.)'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 170,
        'options': ['A. Convert the sharded tables into a single partitioned table',
        'B. Enable query caching so you can cache data from previous months',
        'C. Convert all daily log tables into date-partitioned tables',
        'D. Create separate views to cover each month, and query from these views'],
        'question': 'You launched a new gaming app almost three years ago. You have been uploading log files from the previous day to a separate Google BigQuery table with the table name format LOGS_yyyymmdd. You have been using table wildcard functions to generate daily and monthly reports for all time ranges. Recently you discovered that some queries that cover long date ranges are exceeding the limit of 1000 tables and failing. How can you resolve this issue?'},
    {'answer': 'B',
        'explanation': 'B',
        'id': 171,
        'options': ['A. Build and train a classification model with Spark MLlib to generate labels. Build and train a second classification model with Spark MLlib to filter results to match customer preferences. Deploy the models using Cloud Dataproc. Call the models from your application.',
        "B. Build an application that calls the Cloud Video Intelligence API to generate labels. Store data in Cloud Bigtable, and filter the predicted labels to match the user's viewing history to generate preferences.",
        "C. Build an application that calls the Cloud Video Intelligence API to generate labels. Store data in Cloud SQL, and join and filter the predicted labels to match the user's viewing history to generate preferences.",
        'D. Build and train a complex classification model with Spark MLlib to generate labels and filter the results.,Deploy the models using Cloud Dataproc. Call the model from your application.'],
        'question': 'You are developing an application that uses a recommendation engine on Google Cloud. Your solution should display new videos to customers based on past views. Your solution needs to generate labels for the entities in videos that the customer has viewed. Your design must be able to provide very fast filtering suggestions based on data from other customer preferences on several TB of data. What should you do?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 172,
        'options': ['A. Get more training examples',
        'B. Reduce the number of training examples',
        'C. Use a smaller set of features',
        'D. Increase the regularization parameters ',
        'E. Decrease the regularization parameters',
        'F. Use a larger set of features'],
        'question': 'You are training a spam classifier. You notice that you are overfitting the training data. Which three actions can you take to resolve this problem? (Choose three.)'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 173,
        'options': ['A. Cloud SQL',
        'B. Cloud Datastore',
        'C. Cloud BigTable',
        'D. BigQuery'],
        'question': 'An online retailer has built their current application on Google App Engine. A new initiative at the company mandates that they extend their application to allow their customers to transact directly via the application.They need to manage their shopping transactions and analyze combined data from multiple datasets using a business intelligence (BI) tool. They want to use only a single database for this purpose. Which Google Cloud database should they choose?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 174,
        'options': ['A. Mount the backups to Google Cloud SQL, and then process the data using Google Cloud Dataproc.',
        'B. Connect an on-premises Apache Hadoop cluster to MySQL and perform ETL.',
        'C. Use an ETL tool to load the data from MySQL into Google BigQuery.',
        'D. Add a node to the MySQL cluster and build an OLAP cube there.'],
        'question': "Your company's customer and order databases are often under heavy load. This makes performing analytics against them difficult without harming operations. The databases are in a MySQL cluster, with nightly backups taken using mysqldump. You want to perform analytics with minimal impact on operations. What should you do?"},
    {'answer': 'B',
        'explanation': 'B',
        'id': 175,
        'options': ['A. Set a single global window to capture all the data.',
        'B. Use watermarks and timestamps to capture the lagged data.',
        'C. Set sliding windows to capture all the lagged data.',
        'D. Ensure every datasource type (stream or batch) has a timestamp, and use the timestamps to define the logic for lagged data.'],
        'question': 'Your company receives both batch- and stream-based event data. You want to process the data using Google Cloud Dataflow over a predictable time period. However, you realize that in some instances data can arrive late or out of order. How should you design your Cloud Dataflow pipeline to handle data that is late or out of order?'},
    {'answer': 'E',
        'explanation': 'E',
        'id': 176,
        'options': ['A. Load data into a different dataset for each client.',
        'B. Load data into different partitions.',
        "C. Restrict a client's dataset to approved users.",
        'D. Only allow a service account to access the datasets.',
        "E. Use the appropriate identity and access management (IAM) roles for each client's users.",
        "F. Put each client's BigQuery dataset into a different table."],
        'question': "Your company handles data processing for a number of different clients. Each client prefers to use their own suite of analytics tools, with some allowing direct query access via Google BigQuery. You need to secure the data so that clients cannot see each other's data. You want to ensure appropriate access to the data. Which three steps should you take? (Choose three.)"},
    {'answer': 'D',
        'explanation': 'D',
        'id': 177,
        'options': ['A. Disable caching in BigQuery by editing table details',
        'B. Refresh your browser tab showing the visualizations.',
        'C. Clear your browser history for the past hour then reload the tab showing the virtualizations.',
        'D. Disable caching by editing the report settings.'],
        'question': 'You create an important report for your large team in Google Data Studio 360. The report uses Google BigQuery as its data source. You notice that visualizations are not showing data that is less than 1 hour old. What should you do?'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 178,
        'options': ['A. Cloud Datastore',
        'B. Cloud SQL',
        'C. Cloud Bigtable',
        'D. BigQuery'],
        'question': 'You want to process payment transactions in a point-of-sale application that will run on Google Cloud Platform. Your user base could grow exponentially, but you do not want to manage infrastructure scaling.Which Google database service should you use?'},
    {'answer': 'B',
        'explanation': 'B',
        'id': 179,
        'options': ['A. They have not set the triggers to accommodate the data coming in late, which causes the job to fail',
        'B. They have not applied a non-global windowing function, which causes the job to fail when the pipeline is created',
        'C. They have not assigned the timestamp, which causes the job to fail',
        'D. They have not applied a global windowing function, which causes the job to fail when the pipeline is created'],
        'question': 'Your company is currently setting up data pipelines for their campaign. For all the Google Cloud Pub/Sub streaming data, one of the important business requirements is to be able to periodically identify the inputs and their timings during their campaign. Engineers have decided to use windowing and transformation in Google Cloud Dataflow for this purpose. However, when testing this feature, they find that the Cloud Dataflow job fails for the all streaming insert. What is the most likely cause of this problem?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 180,
        'options': ['A. Create a view CLICK_STREAM_V, where strings from the column DT are cast into TIMESTAMP values. Reference the view CLICK_STREAM_V instead of the table CLICK_STREAM from now on.',
        'B. Add two columns to the table CLICK STREAM: TS of the TIMESTAMP type and IS_NEW of the BOOLEAN type. Reload all data in append mode. For each appended row, set the value of IS_NEW to true. For future queries, reference the column TS instead of the column DT, with the WHERE clause ensuring that the value of IS_NEW must be true.',
        'C. Add a column TS of the TIMESTAMP type to the table CLICK_STREAM, and populate the numeric values from the column TS for each row. Reference the column TS instead of the column DT from now on',
        'D. Construct a query to return every row of the table CLICK_STREAM, while using the built-in function to cast strings from the column DT into TIMESTAMP values. Run the query into a destination table NEW_CLICK_STREAM, in which the column TS is the TIMESTAMP type.Reference the table NEW_CLICK_STREAM instead of the table CLICK_STREAM from now on. In the future, new data is loaded into the table NEW_CLICK_STREAM.',
        'E. Delete the table CLICK_STREAM, and then re-create it such that the column DT is of the TIMESTAMP type. Reload the data.'],
        'question': 'You have spent a few days loading data from comma-separated values (CSV) files into the Google BigQuery table CLICK_STREAM. The column DT stores the epoch time of click events. For convenience, you chose a simple schema where every field is treated as the STRING type. Now, you want to compute web session durations of users who visit your site, and you want to change its data type to the TIMESTAMP. You want to minimize the migration effort without making future queries computationally expensive. What should you do?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 181,
        'options': ['A. Transform text files to compressed Avro using Cloud Dataflow. Use Cloud Storage and BigQuery permanent linked tables for query.',
        'B. Compress text files to gzip using the Grid Computing Tools. Use BigQuery for storage and query.',
        'C. Compress text files to gzip using the Grid Computing Tools. Use Cloud Storage, and then import into Cloud Bigtable for query.',
        'D. Transform text files to compressed Avro using Cloud Dataflow. Use BigQuery for storage and query.'],
        'question': 'You are designing storage for very large text files for a data pipeline on Google Cloud. You want to support ANSI SQL queries. You also want to support compression and parallel load from the input locations using Google recommended practices. What should you do?'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 182,
        'options': ['A. Use a sliding time window with a duration of 60 minutes.',
        'B. Use a fixed-time window with a duration of 60 minutes.',
        'C. Use a global window with a time based trigger with a delay of 60 minutes.',
        'D. Use a session window with a gap time duration of 60 minutes.'],
        'question': 'You are designing a basket abandonment system for an ecommerce company. The system will send a message to a user based on these rules:No interaction by the user on the site for 1 hour,Has added more than $30 worth of products to the basket,Has not completed a transaction.You use Google Cloud Dataflow to process the data and decide if a message should be sent. How should you design the pipeline?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 183,
        'options': ['A. Use the Google Cloud Billing API to see what account the warehouse is being billed to.',
        'B. Use Stackdriver Monitoring to see the usage of BigQuery query slots.',
        'C. Get the identity and access management IAM policy of each table',
        'D. Use Google Stackdriver Audit Logs to review data access.'],
        'question': 'Your startup has never implemented a formal security policy. Currently, everyone in the company has access to the datasets stored in Google BigQuery. Teams have freedom to use the service as they see fit, and they have not documented their use cases. You have been asked to secure the data warehouse. You need to discover what everyone is doing. What should you do first?'},
    {'answer': 'E',
        'explanation': 'E',
        'id': 184,
        'options': ['A. You already have labels for which samples are mutated and which are normal in the database.',
        'B. There are roughly equal occurrences of both normal and mutated samples in the database.',
        'C. You expect future mutations to have different features from the mutated samples in the database',
        'D. There are very few occurrences of mutations relative to normal samples.',
        'E. You expect future mutations to have similar features to the mutated samples in the database.'],
        'question': 'You want to use a database of information about tissue samples to classify future tissue samples as either normal or mutated. You are evaluating an unsupervised anomaly detection method for classifying the tissue samples. Which two characteristic support this method? (Choose two.)'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 185,
        'options': ['A. Redesign the schema to use row keys based on numeric IDs that increase sequentially per user viewing the offers.',
        'B. Redesign the schema to use a single row key to identify values that need to be updated frequently in the cluster.',
        'C. The performance issue should be resolved over time as the site of the BigDate cluster is increased.',
        'D. Redefine the schema by evenly distributing reads and writes across the row space of the table.'],
        'question': 'Your company is running their first dynamic campaign, serving different offers by analyzing real-time data during the holiday season. The data scientists are collecting terabytes of data that rapidly grows every hour during their 30-day campaign. They are using Google Cloud Dataflow to preprocess the data and collect the feature (signals) data that is needed for the machine learning model in Google Cloud Bigtable. The team is observing suboptimal performance with reads and writes of their initial load of 10 TB of data. They want to improve this performance while minimizing cost. What should they do?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 186,
        'options': ['A. Export logs in batch to Google Cloud Storage and then spin up a Google Cloud SQL instance, import the data from Cloud Storage, and run an analysis as needed.',
        'B. Send the data to Cloud Storage and then spin up an Apache Hadoop cluster as needed in Google Cloud Dataproc whenever analysis is required.',
        'C. Send the data to Google Cloud Datastore and then export to BigQuery.',
        'D. Send the data to Google Cloud Pub/Sub, stream Cloud Pub/Sub to Google Cloud Dataflow, and store the data in Google BigQuery.'],
        'question': 'You are deploying 10,000 new Internet of Things devices to collect temperature data in your warehouses globally. You need to process, store and analyze these very large datasets in real time. What should you do?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 187,
        'options': ['A. Use a row key of the form <timestamp>.',
        'B. Use a row key of the form <sensorid>.',
        'C. Use a row key of the form <timestamp>#<sensorid>.',
        'D. Use a row key of the form >#<sensorid>#<timestamp>.'],
        'question': 'Your company is streaming real-time sensor data from their factory floor into Bigtable and they have noticed extremely poor performance. How should the row key be redesigned to improve Bigtable performance on queries that populate real-time dashboards?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 188,
        'options': ['A. Run a local version of Jupiter on the laptop.',
        'B. Host a visualization tool on a VM on Google Compute Engine.',
        'C. Grant the user access to Google Cloud Shell.',
        'D. Deploy Google Cloud Datalab to a virtual machine (VM) on Google Compute Engine.'],
        'question': 'Your company has hired a new data scientist who wants to perform complicated analyses across very large datasets stored in Google Cloud Storage and in a Cassandra cluster on Google Compute Engine. The scientist primarily wants to create labelled data sets for machine learning projects, along with some visualization tasks. She reports that her laptop is not powerful enough to perform her tasks and it is slowing her down. You want to help her perform her tasks. What should you do?'},
    {'answer': 'B',
        'explanation': 'B',
        'id': 189,
        'options': ['A. Create encryption keys in Cloud Key Management Service. Reference those keys in your API service calls when accessing the data in your Compute Engine cluster instances.',
        'B. Create encryption keys in Cloud Key Management Service. Use those keys to encrypt your data in all of the Compute Engine cluster instances.',
        'C. Create a dedicated service account, and use encryption at rest to reference your data stored in your Compute Engine cluster instances as part of your API service calls.',
        'D. Create encryption keys locally. Upload your encryption keys to Cloud Key Management Service. Use those keys to encrypt your data in all of the Compute Engine cluster instances.'],
        'question': 'You set up a streaming data insert into a Redis cluster via a Kafka cluster. Both clusters are running on Compute Engine instances. You need to encrypt data at rest with encryption keys that you can create, rotate, and destroy as needed. What should you do?'},
    {'answer': 'B',
        'explanation': 'B',
        'id': 190,
        'options': ['A. Update the current pipeline and provide the transform mapping JSON object.',
        'B. Update the current pipeline and use the drain flag.',
        'C. Create a new pipeline that has a new Cloud Pub/Sub subscription and cancel the old pipeline.',
        'D. Create a new pipeline that has the same Cloud Pub/Sub subscription and cancel the old pipeline.'],
        'question': 'You have Google Cloud Dataflow streaming pipeline running with a Google Cloud Pub/Sub subscription as the source. You need to make an update to the code that will make the new Cloud Dataflow pipeline incompatible with the current version. You do not want to lose any data when making this update. What should you do?'},
    {'answer': 'D',
        'explanation': 'D',
        'id': 191,
        'options': ['A. Store he common data in the HDFS storage for a Google Cloud Dataproc cluster.',
        'B. Store the common data in BigQuery as partitioned tables.',
        'C. Store the common data in BigQuery and expose authorized views.',
        'D. Store the common data encoded as Avro in Google Cloud Storage.'],
        'question': 'Flowlogistic wants to use Google BigQuery as their primary analysis system, but they still have Apache Hadoop and Spark workloads that they cannot move to BigQuery. Flowlogistic does not know how to store the data that is common to both workloads. What should they do?'},
    {'answer': 'A',
        'explanation': 'A',
        'id': 192,
        'options': ['A. Put the data into Google Cloud Storage.',
        'B. Use preemptible virtual machines (VMs) for the Cloud Dataproc cluster.',
        'C. Migrate some of the cold data into Google Cloud Storage, and keep only the hot data in Persistent Disk.',
        'D. Tune the Cloud Dataproc cluster so that there is just enough disk for all data.'],
        'question': "Your company's on-premises Apache Hadoop servers are approaching end-of-life, and IT has decided to migrate the cluster to Google Cloud Dataproc. A like-for-like migration of the cluster would require 50 TB of Google Persistent Disk per node. The CIO is concerned about the cost of using that much block storage. You want to minimize the storage cost of the migration. What should you do?"},
    {'answer': 'A',
        'explanation': 'A',
        'id': 193,
        'options': ['A. Cloud Pub/Sub, Cloud Dataflow, and Cloud Storage',
        'B. Cloud Load Balancing, Cloud Dataflow, and Cloud Storage',
        'C. Cloud Pub/Sub, Cloud SQL, and Cloud Storage',
        'D. Cloud Pub/Sub, Cloud Dataflow, and Local SSD'],
        'question': "Flowlogistic's management has determined that the current Apache Kafka servers cannot handle the data volume for their real-time inventory tracking system. You need to build a new system on Google Cloud Platform (GCP) that will feed the proprietary tracking software. The system must be able to ingest data from a variety of global sources, process and query in real-time, and store the data reliably. Which combination of GCP products should you choose?"},
    {'answer': 'D',
        'explanation': 'D',
        'id': 194,
        'options': ['A. Use GROUP BY on the unique ID column and timestamp column and SUM on the values.',
        'B. Use the LAG window function with PARTITION by unique ID along with WHERE LAG IS NOT NULL.',
        'C. Include ORDER BY DESK on timestamp column and LIMIT to 1.',
        'D. Use the ROW_NUMBER window function with PARTITION by unique ID along with WHERE row equals 1.'],
        'question': 'You are building new real-time data warehouse for your company and will use Google BigQuery streaming inserts. There is no guarantee that data will only be sent in once but you do have a unique ID for each row of data and an event timestamp. You want to ensure that duplicates are not included while interactively querying data. Which query type should you use?'},
    {'answer': 'F',
        'explanation': 'F',
        'id': 195,
        'options': ['A. Restrict access to tables by role.',
        'B. Use Google Stackdriver Audit Logging to determine policy violations.',
        'C. Segregate data across multiple tables or databases.',
        'D. Ensure that the data is encrypted at all times.',
        'E. Disable writes to certain tables.',
        'F. Restrict BigQuery API access to approved users.'],
        'question': 'Your company is in a highly regulated industry. One of your requirements is to ensure individual users have access only to the minimum amount of information required to do their jobs. You want to enforce this requirement with Google BigQuery. Which three approaches can you take? (Choose three.)'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 196,
        'options': ['A. The Cloud Pub/Sub topic has too many messages published to it.',
        'B. Your custom endpoint has an out-of-date SSL certificate.',
        'C. Your custom endpoint is not acknowledging messages within the acknowledgement deadline.',
        'D. The message body for the sensor event is too large.'],
        'question': 'You work for a car manufacturer and have set up a data pipeline using Google Cloud Pub/Sub to capture anomalous sensor events. You are using a push subscription in Cloud Pub/Sub that calls a custom HTTPS endpoint that you have created to take action of these anomalous events as they occur. Your custom HTTPS endpoint keeps getting an inordinate amount of duplicate messages. What is the most likely cause of these duplicate messages?'},
    {'answer': 'B',
        'explanation': 'B',
        'id': 197,
        'options': ['A. Make a call to the Stackdriver API to list all logs, and apply an advanced filter.',
        'B. Using the Stackdriver API, create a project sink with advanced log filter to export to Pub/Sub, and subscribe to the topic from your monitoring tool.',
        'C. In the Stackdriver logging admin interface, and enable a log sink export to BigQuery.',
        'D. In the Stackdriver logging admin interface, enable a log sink export to Google Cloud Pub/Sub, and subscribe to the topic from your monitoring tool.'],
        'question': 'You want to use Google Stackdriver Logging to monitor Google BigQuery usage. You need an instant notification to be sent to your monitoring tool when new data is appended to a certain table using an insert job, but you do not want to receive notifications for other tables. What should you do?'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 198,
        'options': ['A. Use Cloud Dataflow to run your transformations. Monitor the total execution time for a sampling of jobs. Configure the job to use non-default Compute Engine machine types when needed.',
        'B. Use Cloud Dataproc to run your transformations. Use the diagnose command to generate an operational output archive. Locate the bottleneck and adjust cluster resources.',
        'C. Use Cloud Dataflow to run your transformations. Monitor the job system lag with Stackdriver. Use the default autoscaling setting for worker instances.',
        'D. Use Cloud Dataproc to run your transformations. Monitor CPU utilization for the cluster. Resize the number of worker nodes in your cluster via the command line.'],
        'question': 'You are selecting services to write and transform JSON messages from Cloud Pub/Sub to BigQuery for a data pipeline on Google Cloud. You want to minimize service costs. You also want to monitor and accommodate input data volume that will vary in size with minimal manual intervention. What should you do?'},
    {'answer': 'C',
        'explanation': 'C',
        'id': 199,
        'options': ['A. Assign global unique identifiers (GUID) to each data entry.',
        'B. Store each data entry as the primary key in a separate database and apply an index.',
        'C. Maintain a database table to store the hash value and other metadata for each data entry.',
        'D. Compute the hash value of each data entry, and compare it with all historical data.'],
        'question': 'Your company uses a proprietary system to send inventory data every 6 hours to a data ingestion service in the cloud. Transmitted data includes a payload of several fields and the timestamp of the transmission. If there are any concerns about a transmission, the system re-transmits the data. How should you deduplicate the data most efficiency?'},
    {'answer': 'B',
        'explanation': 'B',
        'id': 200,
        'options': ['A. Import the data in to BigQuery using the gcloud CLI and set max_bad_records to 0.',
        'B. Run a Google Cloud Dataflow batch pipeline to import the data into BigQuery, and push errors to another dead-letter table for analysis.',
        'C. Use federated data sources, and check data in the SQL query.',
        'D. Enable BigQuery monitoring in Google Stackdriver and create an alert.'],
        'question': 'An external customer provides you with a daily dump of data from their database. The data flows into Google Cloud Storage GCS as comma-separated values (CSV) files. You want to analyze this data in Google BigQuery, but the data could have rows that are formatted incorrectly or corrupted. How should you build this pipeline?'}
>>>>>>> bf098eb46bd94d862960666dc9ad29b033b76e5b
];